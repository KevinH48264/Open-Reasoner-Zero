{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pair_prompt = f'''You are a Policy Assistant Evaluator on behalf of the User who set a Policy Assistant Goal. Your task is to evaluate the Current Policy Assistant Responses by selecting 1 response that fulfills MORE of the Policy Assistant Success Criteria provided better than the unselected response, or returning -1 if both responses are equally successful and it is impossible to differentiate which response is better. Show your step-by-step reasoning inside <think> and </think> tags, then provide your final answer inside <answer> and </answer> tags as a response index (0, 1, or -1) for which response fulfills more of the criteria or if they are both equally successful. Note: fulfilling more higher-priority criteria should be considered as fulfilling more of the success criteria than fulfilling more lower-priority criteria.\n",
    "\n",
    "                    \n",
    "# Policy Assistant Goal: \n",
    "Get really good at math. \n",
    "\n",
    "\n",
    "# Policy Assistant Success Criteria:\n",
    "The Policy Assistant Response should be (in order of priority):\n",
    "\n",
    "1) maximizing user and Policy Assistant benefit and helpfulness and minimizing user and Policy Assistant risk, harm, and unwanted outcomes.\n",
    "\n",
    "2) logically correct - the final answer to the problem must be as correct as possible, and as de-risked of being the wrong final answer as much as possible\n",
    "\n",
    "3) clear - the final answer should be unambiguous and directly state the correct result\n",
    "\n",
    "4) concise - the final answer should be free of unnecessary details while still conveying all essential information\n",
    "\n",
    "5) efficient reasoning - even if the reasoning wanders, the path to the final answer should be streamlined and focused\n",
    "\n",
    "6) error minimization - the response should be robust, minimizing the chance of errors in the final answer\n",
    "\n",
    "7) insightfulness - the response should reflect a deep understanding of the problem and apply appropriate techniques\n",
    "\n",
    "8) formatted - the final answer should be between <answer> tags\n",
    "\n",
    "                    \n",
    "# POLICY ASSISTANT PROMPT: \n",
    "\"{prompt}\"\n",
    "\n",
    "\n",
    "# CURRENT POLICY ASSISTANT RESPONSES:\n",
    "Policy Assistant Response 0: \n",
    "\"{resp1}\"\n",
    "\n",
    "\n",
    "Policy Assistant Response 1: \n",
    "\"{resp2}\"'''\n",
    "\n",
    "data_pair = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 4096,\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": pair_prompt,\n",
    "        }]\n",
    "    }],\n",
    "    \"stop\": [\"<|im_end|>\"],\n",
    "    \"n\": 1,\n",
    "    \"model\": \"dev-gpt-4o-vision-2024-05-13\"\n",
    "}\n",
    "pair_data_list.append(data_pair)\n",
    "pair_indices_list.append((idx1, idx2))\n",
    "pair_log_entries.append({\n",
    "    \"prompt\": prompt,\n",
    "    \"pair_indices\": (idx1, idx2),\n",
    "    \"pair_prompt\": pair_prompt,\n",
    "    \"evaluator_response\": None,\n",
    "    \"expected_answer\": extras[idx].get(\"answer\", \"N/A\"),\n",
    "    \"response_0_match_expected\": outputs[idx1][\"iscorrect\"],\n",
    "    \"response_1_match_expected\": outputs[idx2][\"iscorrect\"],\n",
    "})\n",
    "# For an odd leftover, assign default reward 0.5.\n",
    "if len(indices) % 2 == 1:\n",
    "leftover = indices[-1]\n",
    "pairwise_rewards[leftover] = 0.5\n",
    "pair_log_entries.append({\n",
    "    \"prompt\": prompt,\n",
    "    \"pair_indices\": (leftover,),\n",
    "    \"pair_prompt\": \"N/A (odd leftover)\",\n",
    "    \"evaluator_response\": \"N/A\",\n",
    "    \"decision\": \"default 0.5\",\n",
    "    \"expected_answer\": extras[idx].get(\"answer\", \"N/A\"),\n",
    "    \"response_0_match_expected\": outputs[leftover][\"iscorrect\"],\n",
    "})\n",
    "\n",
    "# Define a remote function for GPT-4o pair evaluation.\n",
    "@ray.remote(num_cpus=1)\n",
    "def evaluate_policy_pair(data):\n",
    "url = \"https://skilled-chigger-mentally.ngrok-free.app/api/send_request\"\n",
    "max_retries = 3\n",
    "for attempt in range(max_retries):\n",
    "try:\n",
    "response = requests.post(url, json=data)\n",
    "return response.json()['choices'][0]['message']['content']\n",
    "except Exception as e:\n",
    "logger.error(f\"Error in evaluate_policy_pair attempt {attempt+1}: {e}\")\n",
    "if attempt < max_retries - 1:\n",
    "    import time\n",
    "    time.sleep(2)\n",
    "return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_pair = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 4096,\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": pair_prompt,\n",
    "        }]\n",
    "    }],\n",
    "    \"stop\": [\"<|im_end|>\"],\n",
    "    \"n\": 1,\n",
    "    \"model\": \"dev-gpt-4o-vision-2024-05-13\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
