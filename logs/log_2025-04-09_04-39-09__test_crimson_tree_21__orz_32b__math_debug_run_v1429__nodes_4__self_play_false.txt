[2025-04-09 04:39:21,017] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2025-04-09 04:39:28.242 | INFO     | __main__:PPOExpConfig:160 - prompt_data: ['data/orz_math_57k_collected.json'], eval_prompt_data: ['data/eval_data/math500.json', 'data/eval_data/aime2024.json', 'data/eval_data/gpqa_diamond.json'], prompt_data_probs: [1.0]
2025-04-09 04:39:28.253 | INFO     | __main__:<module>:2792 - --------- config key ---------                  ------ value ------
seed                                            42
ref_num_nodes                                   12
ref_num_gpus_per_node                           1
reward_num_nodes                                12
reward_num_gpus_per_node                        1
actor_num_nodes                                 12
actor_num_gpus_per_node                         1
critic_num_nodes                                12
critic_num_gpus_per_node                        1
colocate_critic_reward                          True
colocate_actor_ref                              True
colocate_all                                    False
vllm_num_engines                                2
vllm_tensor_parallel_size                       4
vllm_sync_backend                               nccl
local_rank                                      -1
pretrain                                        Qwen/Qwen2.5-32B
critic_pretrain                                 Qwen/Qwen2.5-32B
reward_pretrain                                 <class 'NoneType'>
ckpt_path                                       /vc_data_blob/users/kevihuang/models/orz/orz_ckpt/debug_orz_7b_ppo_self_play__math__v1429__self_play_False
save_path                                       /vc_data_blob/users/kevihuang/models/orz/orz_ckpt/debug_orz_7b_ppo_self_play__math__v1429__self_play_False
tensorboard_log_dir                             orz_logs/debug_orz_7b_ppo_self_play__math__v1429__self_play_False
prompt_data                                     <class 'omegaconf.listconfig.ListConfig'>
load_checkpoint                                 True
zero_stage                                      3
bf16                                            True
zpg                                             1
adam_offload                                    False
flash_attn                                      True
grad_accum_dtype                                <class 'NoneType'>
disable_trace_cache                             False
gradient_checkpointing                          True
gradient_checkpointing_use_reentrant            False
disable_fast_tokenizer                          False
target_modules                                  all-linear
enable_prefix_caching                           True
enable_chunked_prefill                          False
max_num_batched_tokens                          2048
enforce_eager                                   False
gpu_memory_utilization                          0.5
eval_steps                                      -1
save_steps                                      -1
save_interval                                   50
actor_learning_rate                             1e-06
critic_learning_rate                            5e-06
num_episodes                                    20
max_epochs                                      1
prompt_max_len                                  8000
generate_max_len                                8000
train_batch_size                                256
micro_train_batch_size                          1
rollout_batch_size                              8
micro_rollout_batch_size                        240
micro_forward_batch_size                        1
policy_update_steps                             1
critic_update_steps                             1
max_len                                         8192
max_norm                                        1.0
num_warmup_steps                                50
l2                                              0.0
eps_clip                                        0.2
value_clip                                      0.2
lambd                                           1.0
gamma                                           1.0
normalize_reward                                True
top_p                                           1.0
temperature                                     1.0
freezing_actor_steps                            -1
n_samples_per_prompt                            8
kl_target                                       <class 'NoneType'>
init_kl_coef                                    0
use_kl_estimator_k3                             True
use_abs_kl                                      False
use_kl_loss                                     True
kl_loss_coef                                    0.0
adam_betas                                      (0.9, 0.95)
reward_clip_range                               (-10, 10)
use_compute_reward_fn                           True
advantage_normalize                             True
value_head_prefix                               value_head
ref_reward_offload                              False
enable_eval                                     True
eval_interval                                   10
update_ref_every_epoch                          True
use_orm_score                                   False
train_num_nodes_per_group                       12
n_policy_evaluator_samples_per_policy_response  2
eval_prompt_data                                <class 'omegaconf.listconfig.ListConfig'>
prompt_data_probs                               <class 'omegaconf.listconfig.ListConfig'>
packing_max_len                                 16384
top_k                                           -1
stop                                            <class 'omegaconf.listconfig.ListConfig'>
use_grpo                                        False
2025-04-09 04:39:28,349	INFO worker.py:1636 -- Connecting to existing Ray cluster at address: 10.4.33.154:6379...
2025-04-09 04:39:28,365	INFO worker.py:1821 -- Connected to Ray cluster.
2025-04-09 04:39:36.892 | INFO     | __main__:train_dataset:2736 - Start processing 56878 dialogues
[36m(LLMActor pid=1734163)[0m Connecting to existing Ray cluster at address: 10.4.33.154:6379...
[36m(LLMActor pid=1734163)[0m Calling ray.init() again after it has already been called.
2025-04-09 04:40:16.476 | INFO     | __main__:train_dataset:2747 - Finished processing 56878 dialogues
2025-04-09 04:40:16.523 | INFO     | __main__:eval_dataset:2765 - Start processing 728 dialogues
2025-04-09 04:40:17.037 | INFO     | __main__:eval_dataset:2786 - Finished processing 728 dialogues
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m [W409 04:41:06.269162225 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Connecting to existing Ray cluster at address: 10.4.33.154:6379...
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Calling ray.init() again after it has already been called.
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:   0%|          | 0/17 [00:00<?, ?it/s]
[36m(CriticRayActorBase pid=1132553, ip=10.4.35.60)[0m [W409 04:41:20.427806900 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())[32m [repeated 24x across cluster][0m
[36m(RefRayActorBase pid=1131859, ip=10.4.35.60)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(PolicyRayActorBase pid=963795, ip=10.4.36.252)[0m Downloading shards:   0%|          | 0/17 [00:00<?, ?it/s][32m [repeated 15x across cluster][0m
[36m(CriticRayActorBase pid=1132553, ip=10.4.35.60)[0m Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]
[36m(CriticRayActorBase pid=1132553, ip=10.4.35.60)[0m Loading checkpoint shards:   6%|▌         | 1/17 [00:00<00:05,  2.72it/s]
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:   6%|▌         | 1/17 [00:15<04:04, 15.28s/it]
[36m(CriticRayActorBase pid=1132553, ip=10.4.35.60)[0m Loading checkpoint shards:  94%|█████████▍| 16/17 [00:03<00:00,  4.53it/s]
[36m(CriticRayActorBase pid=953181, ip=10.4.38.42)[0m [W409 04:41:21.611575604 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())[32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=953181, ip=10.4.38.42)[0m Downloading shards:   0%|          | 0/17 [00:00<?, ?it/s][32m [repeated 8x across cluster][0m
[36m(CriticRayActorBase pid=1132553, ip=10.4.35.60)[0m Loading checkpoint shards: 100%|██████████| 17/17 [00:04<00:00,  4.58it/s]Loading checkpoint shards: 100%|██████████| 17/17 [00:04<00:00,  4.12it/s]
[36m(CriticRayActorBase pid=1132553, ip=10.4.35.60)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[36m(CriticRayActorBase pid=1132553, ip=10.4.35.60)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s][32m [repeated 3x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Loading checkpoint shards:  88%|████████▊ | 15/17 [00:03<00:00,  3.87it/s][32m [repeated 59x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  12%|█▏        | 2/17 [00:29<03:37, 14.49s/it][32m [repeated 16x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Loading checkpoint shards:  94%|█████████▍| 16/17 [00:04<00:00,  3.89it/s][32m [repeated 3x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Loading checkpoint shards: 100%|██████████| 17/17 [00:04<00:00,  3.93it/s]Loading checkpoint shards: 100%|██████████| 17/17 [00:04<00:00,  3.78it/s][32m [repeated 3x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.[32m [repeated 3x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  18%|█▊        | 3/17 [00:43<03:23, 14.51s/it][32m [repeated 16x across cluster][0m
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m Downloading shards:   6%|▌         | 1/17 [00:37<09:57, 37.37s/it][32m [repeated 20x across cluster][0m
[36m(PolicyRayActorBase pid=963801, ip=10.4.36.252)[0m Downloading shards:  24%|██▎       | 4/17 [00:57<03:06, 14.36s/it][32m [repeated 9x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  29%|██▉       | 5/17 [01:11<02:48, 14.03s/it][32m [repeated 16x across cluster][0m
[36m(CriticRayActorBase pid=1735199)[0m Downloading shards:  53%|█████▎    | 9/17 [01:10<00:56,  7.04s/it][32m [repeated 16x across cluster][0m
[36m(CriticRayActorBase pid=953182, ip=10.4.38.42)[0m Downloading shards:  53%|█████▎    | 9/17 [01:15<00:57,  7.14s/it][32m [repeated 36x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  41%|████      | 7/17 [01:40<02:22, 14.23s/it][32m [repeated 10x across cluster][0m
[36m(LLMActor pid=1734163)[0m Loading safetensors checkpoint shards:   0% Completed | 0/17 [00:00<?, ?it/s]
[36m(CriticRayActorBase pid=1735199)[0m Downloading shards: 100%|██████████| 17/17 [01:31<00:00,  4.45s/it]Downloading shards: 100%|██████████| 17/17 [01:31<00:00,  5.37s/it]
[36m(CriticRayActorBase pid=1735199)[0m Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]
[36m(LLMActor pid=1734163)[0m Loading safetensors checkpoint shards:   6% Completed | 1/17 [00:00<00:03,  5.03it/s]
[36m(CriticRayActorBase pid=1735199)[0m Loading checkpoint shards:   6%|▌         | 1/17 [00:00<00:05,  3.12it/s]
[36m(RefRayActorBase pid=964742, ip=10.4.36.252)[0m Downloading shards:  41%|████      | 7/17 [01:40<02:22, 14.23s/it][32m [repeated 15x across cluster][0m
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m Downloading shards:  71%|███████   | 12/17 [01:30<00:32,  6.45s/it]Downloading shards: 100%|██████████| 17/17 [01:30<00:00,  5.33s/it]
[36m(LLMActor pid=1734163)[0m Loading safetensors checkpoint shards:  12% Completed | 2/17 [00:00<00:03,  4.00it/s]
[36m(LLMActor pid=1734163)[0m Loading safetensors checkpoint shards:  18% Completed | 3/17 [00:00<00:03,  3.82it/s]
[36m(CriticRayActorBase pid=1735199)[0m Loading checkpoint shards:  94%|█████████▍| 16/17 [00:03<00:00,  4.29it/s]
[36m(CriticRayActorBase pid=1735199)[0m Loading checkpoint shards: 100%|██████████| 17/17 [00:03<00:00,  4.46it/s]Loading checkpoint shards: 100%|██████████| 17/17 [00:03<00:00,  4.36it/s]
[36m(CriticRayActorBase pid=1735199)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[36m(CriticRayActorBase pid=1735199)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(LLMActor pid=1734163)[0m 
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Loading safetensors checkpoint shards:   0% Completed | 0/17 [00:00<?, ?it/s]
[36m(CriticRayActorBase pid=1735200)[0m Downloading shards: 100%|██████████| 17/17 [01:31<00:00,  4.44s/it]Downloading shards: 100%|██████████| 17/17 [01:31<00:00,  5.37s/it][32m [repeated 3x across cluster][0m
[36m(CriticRayActorBase pid=953181, ip=10.4.38.42)[0m Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m 
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Loading safetensors checkpoint shards: 100% Completed | 17/17 [00:04<00:00,  3.46it/s][32m [repeated 33x across cluster][0m
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m Loading checkpoint shards:  88%|████████▊ | 15/17 [00:03<00:00,  4.01it/s][32m [repeated 119x across cluster][0m
[36m(CriticRayActorBase pid=953181, ip=10.4.38.42)[0m Downloading shards:  71%|███████   | 12/17 [01:30<00:32,  6.46s/it]Downloading shards: 100%|██████████| 17/17 [01:30<00:00,  5.33s/it][32m [repeated 3x across cluster][0m
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m Loading checkpoint shards:  94%|█████████▍| 16/17 [00:04<00:00,  4.14it/s][32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=953181, ip=10.4.38.42)[0m Loading checkpoint shards: 100%|██████████| 17/17 [00:04<00:00,  4.24it/s]Loading checkpoint shards: 100%|██████████| 17/17 [00:04<00:00,  4.06it/s][32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=953181, ip=10.4.38.42)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]
[36m(CriticRayActorBase pid=953182, ip=10.4.38.42)[0m Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  47%|████▋     | 8/17 [01:59<02:22, 15.86s/it]
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m Loading checkpoint shards:  29%|██▉       | 5/17 [00:05<00:14,  1.17s/it][32m [repeated 49x across cluster][0m
[36m(CriticRayActorBase pid=1735200)[0m Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s][32m [repeated 10x across cluster][0m
[36m(RefRayActorBase pid=964742, ip=10.4.36.252)[0m Downloading shards:  47%|████▋     | 8/17 [01:59<02:22, 15.87s/it][32m [repeated 15x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Loading checkpoint shards:  59%|█████▉    | 10/17 [00:11<00:07,  1.04s/it][32m [repeated 60x across cluster][0m
[36m(CriticRayActorBase pid=1735198)[0m Loading checkpoint shards:  94%|█████████▍| 16/17 [00:16<00:00,  1.03it/s]
[36m(CriticRayActorBase pid=1735200)[0m Loading checkpoint shards:  88%|████████▊ | 15/17 [00:16<00:01,  1.02it/s][32m [repeated 71x across cluster][0m
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m Loading checkpoint shards: 100%|██████████| 17/17 [00:17<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 17/17 [00:17<00:00,  1.03s/it]
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m Some weights of CriticModel were not initialized from the model checkpoint at Qwen/Qwen2.5-32B and are newly initialized: ['value_head.weight']
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(CriticRayActorBase pid=1735199)[0m 2025-04-09 04:43:21.133 | INFO     | orz.ppo.models:get_llm_for_sequence_regression:572 - initialize value_head for ZeRO-3 reward model training.
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Using /home/aiscuser/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m Detected CUDA files, patching ldflags
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m Emitting ninja build file /home/aiscuser/.cache/torch_extensions/py310_cu124/fused_adam/build.ninja...
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m /scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m   warnings.warn(
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m Building extension module fused_adam...
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(CriticRayActorBase pid=1735198)[0m Loading extension module fused_adam...
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  53%|█████▎    | 9/17 [02:15<02:07, 16.00s/it]
[36m(CriticRayActorBase pid=1735200)[0m Loading checkpoint shards:  94%|█████████▍| 16/17 [00:17<00:00,  1.01it/s][32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=1735200)[0m Loading checkpoint shards: 100%|██████████| 17/17 [00:17<00:00,  1.13it/s]Loading checkpoint shards: 100%|██████████| 17/17 [00:17<00:00,  1.04s/it][32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=1735200)[0m Some weights of CriticModel were not initialized from the model checkpoint at Qwen/Qwen2.5-32B and are newly initialized: ['value_head.weight'][32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=1735200)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m 2025-04-09 04:43:21.195 | INFO     | orz.ppo.models:get_llm_for_sequence_regression:572 - initialize value_head for ZeRO-3 reward model training.[32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=1735200)[0m Using /home/aiscuser/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...[32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=1132555, ip=10.4.35.60)[0m Detected CUDA files, patching ldflags[32m [repeated 2x across cluster][0m
[36m(CriticRayActorBase pid=1132555, ip=10.4.35.60)[0m Emitting ninja build file /home/aiscuser/.cache/torch_extensions/py310_cu124/fused_adam/build.ninja...[32m [repeated 2x across cluster][0m
[36m(CriticRayActorBase pid=1132555, ip=10.4.35.60)[0m /scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. [32m [repeated 2x across cluster][0m
[36m(CriticRayActorBase pid=1132555, ip=10.4.35.60)[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].[32m [repeated 2x across cluster][0m
[36m(CriticRayActorBase pid=1132555, ip=10.4.35.60)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(CriticRayActorBase pid=1132555, ip=10.4.35.60)[0m Building extension module fused_adam...[32m [repeated 2x across cluster][0m
[36m(CriticRayActorBase pid=1132555, ip=10.4.35.60)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)[32m [repeated 2x across cluster][0m
[36m(CriticRayActorBase pid=953181, ip=10.4.38.42)[0m Loading extension module fused_adam...[32m [repeated 11x across cluster][0m
[36m(PolicyRayActorBase pid=963795, ip=10.4.36.252)[0m Downloading shards:  59%|█████▉    | 10/17 [02:32<01:53, 16.27s/it][32m [repeated 16x across cluster][0m
[36m(PolicyRayActorBase pid=963801, ip=10.4.36.252)[0m Downloading shards:  65%|██████▍   | 11/17 [02:46<01:32, 15.38s/it][32m [repeated 16x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  71%|███████   | 12/17 [03:00<01:15, 15.02s/it][32m [repeated 16x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  76%|███████▋  | 13/17 [03:14<00:59, 14.83s/it][32m [repeated 16x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  82%|████████▏ | 14/17 [03:28<00:43, 14.60s/it][32m [repeated 16x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  88%|████████▊ | 15/17 [03:42<00:28, 14.50s/it][32m [repeated 16x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Downloading shards:  94%|█████████▍| 16/17 [03:56<00:14, 14.25s/it]
[36m(RefRayActorBase pid=964738, ip=10.4.36.252)[0m Downloading shards:  88%|████████▊ | 15/17 [03:43<00:29, 14.52s/it][32m [repeated 15x across cluster][0m
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m Downloading shards: 100%|██████████| 17/17 [04:07<00:00, 13.20s/it]Downloading shards: 100%|██████████| 17/17 [04:07<00:00, 14.53s/it]
[36m(RefRayActorBase pid=964743, ip=10.4.36.252)[0m Downloading shards:  94%|█████████▍| 16/17 [03:56<00:14, 14.26s/it][32m [repeated 15x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]
[36m(RefRayActorBase pid=964742, ip=10.4.36.252)[0m Downloading shards: 100%|██████████| 17/17 [04:07<00:00, 13.21s/it]Downloading shards: 100%|██████████| 17/17 [04:07<00:00, 14.55s/it][32m [repeated 15x across cluster][0m
[36m(RefRayActorBase pid=964742, ip=10.4.36.252)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 15x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Loading checkpoint shards:   6%|▌         | 1/17 [00:02<00:34,  2.14s/it]
[36m(RefRayActorBase pid=1131858, ip=10.4.35.60)[0m Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s][32m [repeated 23x across cluster][0m
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m Loading checkpoint shards:  18%|█▊        | 3/17 [00:07<00:37,  2.69s/it][32m [repeated 48x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Loading checkpoint shards:  29%|██▉       | 5/17 [00:13<00:33,  2.77s/it][32m [repeated 48x across cluster][0m
[36m(RefRayActorBase pid=964738, ip=10.4.36.252)[0m Loading checkpoint shards:  41%|████      | 7/17 [00:18<00:26,  2.62s/it][32m [repeated 48x across cluster][0m
[36m(PolicyRayActorBase pid=1131469, ip=10.4.35.60)[0m Loading checkpoint shards:  53%|█████▎    | 9/17 [00:23<00:20,  2.51s/it][32m [repeated 71x across cluster][0m
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m Loading checkpoint shards:  71%|███████   | 12/17 [00:30<00:11,  2.33s/it][32m [repeated 49x across cluster][0m
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m Loading checkpoint shards:  82%|████████▏ | 14/17 [00:35<00:07,  2.43s/it][32m [repeated 61x across cluster][0m
[36m(PolicyRayActorBase pid=963795, ip=10.4.36.252)[0m Loading checkpoint shards:  94%|█████████▍| 16/17 [00:40<00:02,  2.51s/it]
[36m(PolicyRayActorBase pid=1131469, ip=10.4.35.60)[0m Loading checkpoint shards:  88%|████████▊ | 15/17 [00:37<00:04,  2.46s/it][32m [repeated 34x across cluster][0m
[36m(RefRayActorBase pid=1131859, ip=10.4.35.60)[0m Loading checkpoint shards: 100%|██████████| 17/17 [00:41<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 17/17 [00:41<00:00,  2.47s/it]
[36m(PolicyRayActorBase pid=963795, ip=10.4.36.252)[0m Using /home/aiscuser/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m Detected CUDA files, patching ldflags
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m Emitting ninja build file /home/aiscuser/.cache/torch_extensions/py310_cu124/fused_adam/build.ninja...
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m /scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m   warnings.warn(
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m Building extension module fused_adam...
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m Loading extension module fused_adam...
[36m(RefRayActorBase pid=964741, ip=10.4.36.252)[0m Loading checkpoint shards:  94%|█████████▍| 16/17 [00:40<00:02,  2.50s/it][32m [repeated 23x across cluster][0m
2025-04-09 04:46:30.282 | INFO     | orz.ppo.trainer:build_models:1949 - init policy/ref/critic/reward models done
2025-04-09 04:46:31.364 | INFO     | orz.ppo.trainer:train:79 - Create vllm engine groups done.
2025-04-09 04:48:47.287 | INFO     | orz.ppo.trainer:train:81 - Sync actor weights to vllm engines, time cost: 135.92s
2025-04-09 04:48:47.288 | DEBUG    | orz.ppo.trainer:train:89 - train_dataset size: 56878
2025-04-09 04:48:47.288 | DEBUG    | orz.ppo.trainer:train:90 - train_dataset sample: ('A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\n$P(x)$ is a polynomial of degree $3n$ such that\n\\begin{eqnarray*} P(0) = P(3) = \\cdots &=& P(3n) = 2, \\\\ P(1) = P(4) = \\cdots &=& P(3n-2) = 1, \\\\ P(2) = P(5) = \\cdots &=& P(3n-1) = 0, \\quad\\text{ and }\\\\ && P(3n+1) = 730.\\end{eqnarray*}\nDetermine $n$.\nAssistant: <think>', {'prompt': 'A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\n$P(x)$ is a polynomial of degree $3n$ such that\n\\begin{eqnarray*} P(0) = P(3) = \\cdots &=& P(3n) = 2, \\\\ P(1) = P(4) = \\cdots &=& P(3n-2) = 1, \\\\ P(2) = P(5) = \\cdots &=& P(3n-1) = 0, \\quad\\text{ and }\\\\ && P(3n+1) = 730.\\end{eqnarray*}\nDetermine $n$.\nAssistant: <think>', 'answer': 'n = 4', 'target': 'n = 4'})
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:39:55 config.py:478] This model supports multiple tasks: {'reward', 'classify', 'embed', 'score', 'generate'}. Defaulting to 'generate'.
[36m(LLMActor pid=1734163)[0m WARNING 04-09 04:39:55 cuda.py:98] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(LLMActor pid=1734163)[0m WARNING 04-09 04:39:55 config.py:604] Async output processing is not supported on the current platform type cuda.
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:39:55 llm_engine.py:249] Initializing an LLM engine (v0.6.5) with config: model='Qwen/Qwen2.5-32B', speculative_config=None, tokenizer='Qwen/Qwen2.5-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=43, served_model_name=Qwen/Qwen2.5-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=False, mm_cache_preprocessor=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, 
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:39:56 ray_gpu_executor.py:122] use_ray_spmd_worker: False
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:39:58 config.py:478] This model supports multiple tasks: {'reward', 'generate', 'embed', 'score', 'classify'}. Defaulting to 'generate'.
[36m(pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:40:25,273] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m WARNING 04-09 04:39:58 cuda.py:98] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m WARNING 04-09 04:39:58 config.py:604] Async output processing is not supported on the current platform type cuda.
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:39:58 llm_engine.py:249] Initializing an LLM engine (v0.6.5) with config: model='Qwen/Qwen2.5-32B', speculative_config=None, tokenizer='Qwen/Qwen2.5-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=Qwen/Qwen2.5-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=False, mm_cache_preprocessor=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, 
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:40:00 ray_gpu_executor.py:122] use_ray_spmd_worker: False
[36m(RayWorkerWrapper pid=1734660)[0m INFO 04-09 04:40:38 selector.py:120] Using Flash Attention backend.
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:40:40 utils.py:922] Found nccl from library libnccl.so.2
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:40:40 pynccl.py:69] vLLM is using nccl==2.21.5
[36m(LLMActor pid=1734163)[0m NCCL version 2.21.5+cuda12.4
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:40:41 custom_all_reduce_utils.py:204] generating GPU P2P access cache in /home/aiscuser/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[36m(pid=963797, ip=10.4.36.252)[0m [2025-04-09 04:40:42,344] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(RayWorkerWrapper pid=952872, ip=10.4.38.42)[0m INFO 04-09 04:40:39 selector.py:120] Using Flash Attention backend.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(RayWorkerWrapper pid=952872, ip=10.4.38.42)[0m INFO 04-09 04:40:42 utils.py:922] Found nccl from library libnccl.so.2[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=952872, ip=10.4.38.42)[0m INFO 04-09 04:40:42 pynccl.py:69] vLLM is using nccl==2.21.5[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m NCCL version 2.21.5+cuda12.4
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:40:43 custom_all_reduce_utils.py:204] generating GPU P2P access cache in /home/aiscuser/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[36m(pid=964739, ip=10.4.36.252)[0m [2025-04-09 04:40:57,032] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 12x across cluster][0m
[36m(PolicyRayActorBase pid=1131469, ip=10.4.35.60)[0m [2025-04-09 04:41:06,237] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(pid=964738, ip=10.4.36.252)[0m [2025-04-09 04:40:57,864] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:41:06,238] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(PolicyRayActorBase pid=1131469, ip=10.4.35.60)[0m [2025-04-09 04:41:06,761] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:41:08 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/aiscuser/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:41:08 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_2da1fc12'), local_subscribe_port=58369, remote_subscribe_port=None)
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:41:08 model_runner.py:1092] Starting to load model Qwen/Qwen2.5-32B...
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:41:08 weight_utils.py:243] Using model weights format ['*.safetensors']
[36m(RefRayActorBase pid=964743, ip=10.4.36.252)[0m [2025-04-09 04:41:06,267] [INFO] [comm.py:652:init_distributed] cdb=None[32m [repeated 24x across cluster][0m
[36m(pid=1735199)[0m [2025-04-09 04:41:11,253] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 2x across cluster][0m
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:41:06,268] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl[32m [repeated 2x across cluster][0m
[36m(RefRayActorBase pid=1131859, ip=10.4.35.60)[0m [2025-04-09 04:41:07,543] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:41:14 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/aiscuser/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json[32m [repeated 4x across cluster][0m
[36m(RayWorkerWrapper pid=1734771)[0m INFO 04-09 04:41:08 model_runner.py:1092] Starting to load model Qwen/Qwen2.5-32B...[32m [repeated 3x across cluster][0m
[36m(RayWorkerWrapper pid=1734771)[0m INFO 04-09 04:41:08 weight_utils.py:243] Using model weights format ['*.safetensors'][32m [repeated 3x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:41:14 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_83d7abe5'), local_subscribe_port=53165, remote_subscribe_port=None)
[36m(CriticRayActorBase pid=1132553, ip=10.4.35.60)[0m [2025-04-09 04:41:19,470] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(pid=953184, ip=10.4.38.42)[0m [2025-04-09 04:41:12,936] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 9x across cluster][0m
[36m(CriticRayActorBase pid=1132554, ip=10.4.35.60)[0m [2025-04-09 04:41:19,773] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(RayWorkerWrapper pid=952872, ip=10.4.38.42)[0m INFO 04-09 04:41:14 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/aiscuser/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json[32m [repeated 3x across cluster][0m
[36m(RayWorkerWrapper pid=952872, ip=10.4.38.42)[0m INFO 04-09 04:41:15 model_runner.py:1092] Starting to load model Qwen/Qwen2.5-32B...[32m [repeated 4x across cluster][0m
[36m(RayWorkerWrapper pid=952872, ip=10.4.38.42)[0m INFO 04-09 04:41:15 weight_utils.py:243] Using model weights format ['*.safetensors'][32m [repeated 4x across cluster][0m
[36m(CriticRayActorBase pid=1132553, ip=10.4.35.60)[0m [2025-04-09 04:41:25,679] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m [2025-04-09 04:41:21,654] [INFO] [comm.py:652:init_distributed] cdb=None[32m [repeated 9x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m NCCL version 2.21.5+cuda12.4
[36m(CriticRayActorBase pid=1735199)[0m [2025-04-09 04:42:57,185] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12[32m [repeated 4x across cluster][0m
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:42:57 model_runner.py:1097] Loading model weights took 15.4136 GB
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:03,459] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 771, num_elems = 31.99B
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m [2025-04-09 04:42:58,060] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=952662, ip=10.4.38.42)[0m INFO 04-09 04:43:00 model_runner.py:1097] Loading model weights took 15.4136 GB[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=1734496)[0m INFO 04-09 04:43:10 worker.py:241] Memory profiling takes 10.71 seconds
[36m(RayWorkerWrapper pid=1734496)[0m INFO 04-09 04:43:10 worker.py:241] the current vLLM instance can use total_gpu_memory (79.15GiB) x gpu_memory_utilization (0.50) = 39.58GiB
[36m(RayWorkerWrapper pid=1734496)[0m INFO 04-09 04:43:10 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 2.21GiB; PyTorch activation peak memory takes 0.72GiB; the rest of the memory reserved for KV Cache is 21.24GiB.
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:43:10 distributed_gpu_executor.py:57] # GPU blocks: 1310, # CPU blocks: 256
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:43:10 distributed_gpu_executor.py:61] Maximum concurrency for 8192 tokens per request: 40.94x
[36m(LLMActor pid=1734163)[0m INFO 04-09 04:43:12 llm_engine.py:446] init engine (profile, create kv cache, warmup model) took 13.25 seconds
[36m(CriticRayActorBase pid=1735198)[0m ninja: no work to do.
[36m(CriticRayActorBase pid=1735198)[0m Time to load fused_adam op: 2.6810402870178223 seconds
[36m(CriticRayActorBase pid=1735198)[0m [2025-04-09 04:43:23,948] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:43:11 worker.py:241] Memory profiling takes 11.22 seconds[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:43:11 worker.py:241] the current vLLM instance can use total_gpu_memory (79.15GiB) x gpu_memory_utilization (0.50) = 39.58GiB[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:43:11 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 2.30GiB; PyTorch activation peak memory takes 1.38GiB; the rest of the memory reserved for KV Cache is 20.48GiB.[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:43:11 distributed_gpu_executor.py:57] # GPU blocks: 1310, # CPU blocks: 256
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:43:11 distributed_gpu_executor.py:61] Maximum concurrency for 8192 tokens per request: 40.94x
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m INFO 04-09 04:43:14 llm_engine.py:446] init engine (profile, create kv cache, warmup model) took 13.82 seconds
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,293] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.0, git-hash=unknown, git-branch=unknown
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,293] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,309] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,310] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,310] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,375] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,375] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,375] [INFO] [logging.py:128:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,375] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,596] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,597] [INFO] [utils.py:782:see_memory_usage] MA 5.01 GB         Max_MA 7.91 GB         CA 8.38 GB         Max_CA 8 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,597] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 77.1 GB, percent = 4.4%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,600] [INFO] [stage3.py:167:__init__] Reduce bucket size 500000000
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,600] [INFO] [stage3.py:168:__init__] Prefetch bucket size 50000000
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,822] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,822] [INFO] [utils.py:782:see_memory_usage] MA 5.01 GB         Max_MA 5.01 GB         CA 8.38 GB         Max_CA 8 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:24,823] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 77.11 GB, percent = 4.4%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Parameter Offload: Total persistent parameters: 1124352 in 322 params
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:25,082] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:25,083] [INFO] [utils.py:782:see_memory_usage] MA 5.01 GB         Max_MA 5.01 GB         CA 8.38 GB         Max_CA 8 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:25,083] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 77.11 GB, percent = 4.4%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:25,309] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:25,310] [INFO] [utils.py:782:see_memory_usage] MA 5.01 GB         Max_MA 5.01 GB         CA 8.38 GB         Max_CA 8 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:25,310] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 77.1 GB, percent = 4.4%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:27,399] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 4
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:27,400] [INFO] [utils.py:782:see_memory_usage] MA 4.96 GB         Max_MA 5.01 GB         CA 4.97 GB         Max_CA 8 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:27,400] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 85.84 GB, percent = 4.8%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:27,631] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:27,632] [INFO] [utils.py:782:see_memory_usage] MA 4.96 GB         Max_MA 4.96 GB         CA 4.97 GB         Max_CA 5 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:27,632] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 86.85 GB, percent = 4.9%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:27,892] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:27,892] [INFO] [utils.py:782:see_memory_usage] MA 14.9 GB         Max_MA 16.13 GB         CA 16.77 GB         Max_CA 17 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:27,893] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 87.0 GB, percent = 4.9%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:28,847] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:28,848] [INFO] [utils.py:782:see_memory_usage] MA 14.9 GB         Max_MA 14.9 GB         CA 16.77 GB         Max_CA 17 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:28,848] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 77.05 GB, percent = 4.3%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:29,084] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:29,085] [INFO] [utils.py:782:see_memory_usage] MA 14.9 GB         Max_MA 18.63 GB         CA 20.5 GB         Max_CA 20 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:29,085] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 77.05 GB, percent = 4.3%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:29,086] [INFO] [stage3.py:525:_setup_for_real_optimizer] optimizer state initialized
[36m(CriticRayActorBase pid=953183, ip=10.4.38.42)[0m ninja: no work to do.[32m [repeated 2x across cluster][0m
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m Time to load fused_adam op: 3.022324800491333 seconds[32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=953184, ip=10.4.38.42)[0m [2025-04-09 04:43:24,290] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12[32m [repeated 11x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,930] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,931] [INFO] [utils.py:782:see_memory_usage] MA 25.76 GB         Max_MA 28.66 GB         CA 30.43 GB         Max_CA 30 GB 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,931] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 77.06 GB, percent = 4.3%
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,932] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,932] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,932] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f6273680490>
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,932] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,934] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,934] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "partition_activations": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "contiguous_memory_optimization": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "cpu_checkpointing": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "number_checkpoints": null, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "synchronize_checkpoint_boundary": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "profile": false
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m }
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,934] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,934] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "enabled": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "start_step": null, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "end_step": null, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "metric_path": null, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "arg_mappings": null, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "metric": "throughput", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "model_info": null, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "results_dir": "autotuning_results", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "exps_dir": "autotuning_exps", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "overwrite": true, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "fast": true, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "start_profile_step": 3, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "end_profile_step": 5, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "tuner_type": "gridsearch", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "tuner_early_stopping": 5, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "tuner_num_trials": 50, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "model_info_path": null, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "mp_size": 1, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "max_train_batch_size": null, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "min_train_batch_size": 1, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "num_tuning_micro_batch_sizes": 3
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m }
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6271fbe890>
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,935] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "enabled": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "recompute_fwd_factor": 0.0, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "profile_step": 1, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "module_depth": -1, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "top_modules": 1, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "detailed": true, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "output_file": null
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m }
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   grad_accum_dtype ............. fp32
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "enabled": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "persistent_storage_path": null, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "persistent_time_interval": 100, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "num_of_version_in_retention": 2, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "enable_nebula_load": true, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "load_path": null
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m }
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,936] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   train_batch_size ............. 12
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   world_size ................... 12
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m [2025-04-09 04:43:30,937] [INFO] [config.py:989:print_user_config]   json = {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "steps_per_print": 100, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "zero_optimization": {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "stage": 3, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "offload_param": {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m             "device": "none"
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         }, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "offload_optimizer": {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m             "device": "none", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m             "pin_memory": true
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         }, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "sub_group_size": "auto", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "stage3_max_live_parameters": "auto", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "stage3_max_reuse_distance": "auto", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "reduce_bucket_size": "auto", 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "zero_hpz_partition_size": 1, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "zero_quantized_weights": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "zero_quantized_gradients": false
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     }, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "bf16": {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "enabled": true
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     }, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "gradient_clipping": 1.0, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "prescale_gradients": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "wall_clock_breakdown": false, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "data_types": {
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m         "grad_accum_dtype": "fp32"
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     }, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "train_micro_batch_size_per_gpu": 1, 
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m     "gradient_accumulation_steps": 1
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m }
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m [2025-04-09 04:45:15,758] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12
[36m(RefRayActorBase pid=964739, ip=10.4.36.252)[0m [2025-04-09 04:45:15,761] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m NCCL version 2.21.5+cuda12.4
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:45:37,943] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 771, num_elems = 32.76B
[36m(RefRayActorBase pid=964742, ip=10.4.36.252)[0m [2025-04-09 04:45:15,773] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12[32m [repeated 14x across cluster][0m
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m NCCL version 2.21.5+cuda12.4
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:45:37,985] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 771, num_elems = 32.76B
[36m(RefRayActorBase pid=1131859, ip=10.4.35.60)[0m [2025-04-09 04:46:20,207] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12
[36m(RefRayActorBase pid=1131861, ip=10.4.35.60)[0m [2025-04-09 04:46:20,211] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,302] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.0, git-hash=unknown, git-branch=unknown
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,302] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,318] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,321] [INFO] [logging.py:128:log_dist] [Rank 0] Creating ZeRO Offload
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,528] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,529] [INFO] [utils.py:782:see_memory_usage] MA 5.13 GB         Max_MA 8.03 GB         CA 8.38 GB         Max_CA 8 GB 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,529] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 74.95 GB, percent = 4.2%
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m Parameter Offload: Total persistent parameters: 1119232 in 321 params
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,776] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,777] [INFO] [utils.py:782:see_memory_usage] MA 5.13 GB         Max_MA 5.13 GB         CA 8.38 GB         Max_CA 8 GB 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,777] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 74.95 GB, percent = 4.2%
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,779] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,779] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "partition_activations": false, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "contiguous_memory_optimization": false, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "cpu_checkpointing": false, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "number_checkpoints": null, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "synchronize_checkpoint_boundary": false, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "profile": false
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m }
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,779] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,779] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,779] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "enabled": false, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "start_step": null, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "end_step": null, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "metric_path": null, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "arg_mappings": null, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "metric": "throughput", 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "model_info": null, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "results_dir": "autotuning_results", 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "exps_dir": "autotuning_exps", 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "overwrite": true, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "fast": true, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "start_profile_step": 3, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "end_profile_step": 5, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "tuner_type": "gridsearch", 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "tuner_early_stopping": 5, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "tuner_num_trials": 50, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "model_info_path": null, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "mp_size": 1, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "max_train_batch_size": null, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "min_train_batch_size": 1, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "num_tuning_micro_batch_sizes": 3
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m }
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f69f42f16c0>
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "enabled": false, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "recompute_fwd_factor": 0.0, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "profile_step": 1, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "module_depth": -1, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "top_modules": 1, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "detailed": true, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "output_file": null
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m }
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,780] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "enabled": false, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "persistent_storage_path": null, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "persistent_time_interval": 100, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "num_of_version_in_retention": 2, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "enable_nebula_load": true, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "load_path": null
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m }
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   train_batch_size ............. 12
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,781] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:1003:print]   world_size ................... 12
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m [2025-04-09 04:46:20,782] [INFO] [config.py:989:print_user_config]   json = {
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "steps_per_print": 100, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "zero_optimization": {
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m         "stage": 3, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m         "offload_param": {
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m             "device": "none", 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m             "pin_memory": true
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m         }
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     }, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "bf16": {
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m         "enabled": true
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     }, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "gradient_clipping": 1.0, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "prescale_gradients": false, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "wall_clock_breakdown": false, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "train_micro_batch_size_per_gpu": 1, 
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m     "gradient_accumulation_steps": 1
[36m(RefRayActorBase pid=963799, ip=10.4.36.252)[0m }
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m ninja: no work to do.
[36m(PolicyRayActorBase pid=963800, ip=10.4.36.252)[0m Time to load fused_adam op: 2.6728625297546387 seconds
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,177] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,177] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,237] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,237] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,237] [INFO] [logging.py:128:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,237] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,453] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,458] [INFO] [stage3.py:167:__init__] Reduce bucket size 500000000
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,458] [INFO] [stage3.py:168:__init__] Prefetch bucket size 50000000
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:24,168] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:27,466] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 4
[36m(PolicyRayActorBase pid=1131467, ip=10.4.35.60)[0m [2025-04-09 04:46:23,440] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 12[32m [repeated 22x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,159] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.0, git-hash=unknown, git-branch=unknown
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,160] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,175] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,693] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:27,467] [INFO] [utils.py:782:see_memory_usage] MA 5.09 GB         Max_MA 5.13 GB         CA 5.09 GB         Max_CA 8 GB [32m [repeated 5x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:27,467] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 74.91 GB, percent = 4.2%[32m [repeated 5x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Parameter Offload: Total persistent parameters: 1119232 in 321 params
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:23,955] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:27,678] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:27,930] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:28,144] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m ninja: no work to do.
[36m(PolicyRayActorBase pid=1131467, ip=10.4.35.60)[0m Time to load fused_adam op: 3.019256353378296 seconds[32m [repeated 11x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:28,361] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:28,363] [INFO] [stage3.py:525:_setup_for_real_optimizer] optimizer state initialized
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,270] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,271] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,271] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,271] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7faf36e822f0>
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,271] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,273] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "partition_activations": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "contiguous_memory_optimization": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "cpu_checkpointing": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "number_checkpoints": null, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "synchronize_checkpoint_boundary": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "profile": false
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m }
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "enabled": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "start_step": null, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "end_step": null, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "metric_path": null, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "arg_mappings": null, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "metric": "throughput", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "model_info": null, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "results_dir": "autotuning_results", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "exps_dir": "autotuning_exps", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "overwrite": true, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "fast": true, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "start_profile_step": 3, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "end_profile_step": 5, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "tuner_type": "gridsearch", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "tuner_early_stopping": 5, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "tuner_num_trials": 50, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "model_info_path": null, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "mp_size": 1, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "max_train_batch_size": null, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "min_train_batch_size": 1, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "num_tuning_micro_batch_sizes": 3
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m }
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7faf36cda9e0>
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,274] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "enabled": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "recompute_fwd_factor": 0.0, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "profile_step": 1, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "module_depth": -1, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "top_modules": 1, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "detailed": true, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "output_file": null
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m }
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   grad_accum_dtype ............. fp32
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,275] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "enabled": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "persistent_storage_path": null, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "persistent_time_interval": 100, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "num_of_version_in_retention": 2, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "enable_nebula_load": true, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "load_path": null
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m }
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   train_batch_size ............. 12
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   world_size ................... 12
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,276] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,277] [INFO] [config.py:989:print_user_config]   json = {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "steps_per_print": 100, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "zero_optimization": {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "stage": 3, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "offload_param": {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m             "device": "none"
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         }, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "offload_optimizer": {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m             "device": "none", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m             "pin_memory": true
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         }, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "sub_group_size": "auto", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "stage3_max_live_parameters": "auto", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "stage3_max_reuse_distance": "auto", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "reduce_bucket_size": "auto", 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "zero_hpz_partition_size": 1, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "zero_quantized_weights": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "zero_quantized_gradients": false
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     }, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "bf16": {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "enabled": true
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     }, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "gradient_clipping": 1.0, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "prescale_gradients": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "wall_clock_breakdown": false, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "data_types": {
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m         "grad_accum_dtype": "fp32"
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     }, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "train_micro_batch_size_per_gpu": 1, 
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m     "gradient_accumulation_steps": 1
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m }
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m WARNING:using --vllm_sync_backend=gloo for vLLM version > 0.4.2 (or export NCCL_P2P_DISABLE=1)
[36m(LLMActor pid=1734163)[0m init_process_group: master_address=10.4.36.252, master_port=43001,  rank=5, world_size=9, group_name=openrlhf
Episode [1/20]:   0%|          | 0/7110 [00:00<?, ?it/s][36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Broadcast actor weights to vllm engines done
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,271] [INFO] [utils.py:782:see_memory_usage] MA 26.36 GB         Max_MA 29.26 GB         CA 31.03 GB         Max_CA 31 GB [32m [repeated 5x across cluster][0m
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m [2025-04-09 04:46:30,271] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 74.91 GB, percent = 4.2%[32m [repeated 5x across cluster][0m
[36m(RayWorkerWrapper pid=952872, ip=10.4.38.42)[0m init_process_group: master_address=10.4.36.252, master_port=43001,  rank=4, world_size=9, group_name=openrlhf[32m [repeated 7x across cluster][0m
2025-04-09 04:48:47.548 | INFO     | __main__:eval:2597 - Start evaluating on val set
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:   0%|          | 0/364 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(PolicyRayActorBase pid=1131469, ip=10.4.35.60)[0m Loading checkpoint shards: 100%|██████████| 17/17 [00:42<00:00,  2.28s/it]Loading checkpoint shards: 100%|██████████| 17/17 [00:42<00:00,  2.48s/it][32m [repeated 23x across cluster][0m
[36m(PolicyRayActorBase pid=1131470, ip=10.4.35.60)[0m Using /home/aiscuser/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...[32m [repeated 11x across cluster][0m
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m Detected CUDA files, patching ldflags
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m Emitting ninja build file /home/aiscuser/.cache/torch_extensions/py310_cu124/fused_adam/build.ninja...
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m /scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m   warnings.warn(
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m Building extension module fused_adam...
[36m(PolicyRayActorBase pid=1131468, ip=10.4.35.60)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(PolicyRayActorBase pid=1131467, ip=10.4.35.60)[0m Loading extension module fused_adam...[32m [repeated 11x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:   0%|          | 1/364 [00:07<44:51,  7.41s/it, est. speed input: 27.78 toks/s, output: 3.51 toks/s]
[36m(LLMActor pid=1734163)[0m Processed prompts:   0%|          | 0/364 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:   1%|          | 2/364 [00:08<20:47,  3.45s/it, est. speed input: 43.80 toks/s, output: 7.05 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:   4%|▍         | 15/364 [00:12<01:53,  3.07it/s, est. speed input: 234.67 toks/s, output: 56.49 toks/s][32m [repeated 17x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  12%|█▏        | 42/364 [00:17<00:52,  6.16it/s, est. speed input: 450.28 toks/s, output: 163.51 toks/s][32m [repeated 36x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  20%|█▉        | 72/364 [00:22<00:48,  6.04it/s, est. speed input: 589.43 toks/s, output: 263.12 toks/s][32m [repeated 35x across cluster][0m
[36m(LLMActor pid=1734163)[0m Processed prompts:  19%|█▊        | 68/364 [00:27<01:22,  3.60it/s, est. speed input: 626.37 toks/s, output: 209.76 toks/s][32m [repeated 34x across cluster][0m
[36m(LLMActor pid=1734163)[0m Processed prompts:  25%|██▌       | 91/364 [00:33<00:48,  5.60it/s, est. speed input: 704.12 toks/s, output: 281.77 toks/s][32m [repeated 38x across cluster][0m
[36m(LLMActor pid=1734163)[0m Processed prompts:  31%|███       | 112/364 [00:38<01:08,  3.68it/s, est. speed input: 760.47 toks/s, output: 342.42 toks/s][32m [repeated 38x across cluster][0m
[36m(LLMActor pid=1734163)[0m Processed prompts:  39%|███▉      | 142/364 [00:43<00:36,  6.11it/s, est. speed input: 854.88 toks/s, output: 437.60 toks/s][32m [repeated 46x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  73%|███████▎  | 264/364 [00:48<00:14,  7.07it/s, est. speed input: 1042.94 toks/s, output: 860.19 toks/s][32m [repeated 39x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  83%|████████▎ | 302/364 [00:53<00:07,  8.01it/s, est. speed input: 1103.08 toks/s, output: 989.42 toks/s][32m [repeated 37x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  90%|████████▉ | 326/364 [00:58<00:05,  6.92it/s, est. speed input: 1092.38 toks/s, output: 1043.12 toks/s][32m [repeated 34x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  92%|█████████▏| 334/364 [01:01<00:09,  3.08it/s, est. speed input: 1087.50 toks/s, output: 1056.11 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  92%|█████████▏| 335/364 [01:01<00:09,  3.09it/s, est. speed input: 1084.60 toks/s, output: 1056.33 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  92%|█████████▏| 336/364 [01:02<00:12,  2.17it/s, est. speed input: 1070.65 toks/s, output: 1045.98 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  93%|█████████▎| 337/364 [01:03<00:16,  1.68it/s, est. speed input: 1059.10 toks/s, output: 1034.61 toks/s]
[36m(LLMActor pid=1734163)[0m Processed prompts:  76%|███████▌  | 276/364 [01:03<00:09,  8.83it/s, est. speed input: 1186.31 toks/s, output: 883.38 toks/s][32m [repeated 21x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  93%|█████████▎| 338/364 [01:04<00:18,  1.42it/s, est. speed input: 1046.73 toks/s, output: 1026.45 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  93%|█████████▎| 339/364 [01:04<00:16,  1.56it/s, est. speed input: 1043.02 toks/s, output: 1025.20 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  93%|█████████▎| 340/364 [01:05<00:13,  1.82it/s, est. speed input: 1040.75 toks/s, output: 1026.37 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  94%|█████████▎| 341/364 [01:05<00:11,  2.07it/s, est. speed input: 1038.50 toks/s, output: 1029.68 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  94%|█████████▍| 342/364 [01:06<00:13,  1.63it/s, est. speed input: 1027.11 toks/s, output: 1023.57 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  94%|█████████▍| 343/364 [01:06<00:11,  1.84it/s, est. speed input: 1023.97 toks/s, output: 1024.24 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  95%|█████████▍| 344/364 [01:07<00:11,  1.77it/s, est. speed input: 1017.61 toks/s, output: 1021.17 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  95%|█████████▍| 345/364 [01:07<00:10,  1.88it/s, est. speed input: 1014.10 toks/s, output: 1020.20 toks/s]
[36m(LLMActor pid=1734163)[0m Processed prompts:  81%|████████  | 294/364 [01:08<00:17,  4.08it/s, est. speed input: 1166.64 toks/s, output: 921.68 toks/s][32m [repeated 13x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  95%|█████████▌| 346/364 [01:09<00:17,  1.04it/s, est. speed input: 987.95 toks/s, output: 997.37 toks/s]  
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  95%|█████████▌| 347/364 [01:10<00:15,  1.08it/s, est. speed input: 979.35 toks/s, output: 993.51 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  96%|█████████▌| 348/364 [01:11<00:12,  1.31it/s, est. speed input: 976.67 toks/s, output: 996.83 toks/s]
[36m(LLMActor pid=1734163)[0m Processed prompts:  88%|████████▊ | 321/364 [01:14<00:09,  4.39it/s, est. speed input: 1194.43 toks/s, output: 1017.64 toks/s][32m [repeated 18x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  96%|█████████▌| 349/364 [01:14<00:23,  1.56s/it, est. speed input: 934.43 toks/s, output: 959.98 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  96%|█████████▌| 350/364 [01:16<00:22,  1.58s/it, est. speed input: 919.62 toks/s, output: 946.52 toks/s]
[36m(LLMActor pid=1734163)[0m Processed prompts:  91%|█████████ | 332/364 [01:17<00:10,  3.09it/s, est. speed input: 1191.70 toks/s, output: 1052.67 toks/s][32m [repeated 9x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  97%|█████████▋| 352/364 [01:19<00:19,  1.64s/it, est. speed input: 883.56 toks/s, output: 922.98 toks/s][32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1734163)[0m Processed prompts:  96%|█████████▌| 350/364 [01:27<00:16,  1.17s/it, est. speed input: 1122.55 toks/s, output: 1046.84 toks/s][32m [repeated 13x across cluster][0m
[36m(LLMActor pid=1734163)[0m Processed prompts:  98%|█████████▊| 356/364 [01:32<00:06,  1.21it/s, est. speed input: 1078.08 toks/s, output: 1032.73 toks/s][32m [repeated 7x across cluster][0m
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  99%|█████████▉| 361/364 [01:38<00:11,  3.92s/it, est. speed input: 735.21 toks/s, output: 810.63 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMActor pid=1734163)[0m Processed prompts:  99%|█████████▉| 362/364 [01:44<00:03,  1.85s/it, est. speed input: 974.72 toks/s, output: 964.42 toks/s][32m [repeated 4x across cluster][0m
[36m(LLMActor pid=1734163)[0m Processed prompts: 100%|█████████▉| 363/364 [01:51<00:03,  3.37s/it, est. speed input: 917.24 toks/s, output: 912.05 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts:  99%|█████████▉| 362/364 [01:52<00:13,  6.90s/it, est. speed input: 644.48 toks/s, output: 717.97 toks/s]
[36m(LLMActor pid=1734163)[0m Processed prompts: 100%|██████████| 364/364 [02:03<00:00,  6.11s/it, est. speed input: 826.99 toks/s, output: 829.83 toks/s]Processed prompts: 100%|██████████| 364/364 [02:03<00:00,  2.94it/s, est. speed input: 826.99 toks/s, output: 829.83 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts: 100%|█████████▉| 363/364 [02:19<00:12, 12.64s/it, est. speed input: 523.61 toks/s, output: 592.55 toks/s]
[36m(LLMActor pid=952424, ip=10.4.38.42)[0m Processed prompts: 100%|██████████| 364/364 [02:27<00:00, 11.23s/it, est. speed input: 497.14 toks/s, output: 571.34 toks/s]Processed prompts: 100%|██████████| 364/364 [02:27<00:00,  2.47it/s, est. speed input: 497.14 toks/s, output: 571.34 toks/s]
2025-04-09 04:51:17.549 | INFO     | __main__:eval:2709 - math500/response_len_in_char: 698.5460,math500/accuracy: 0.1760,aime2024/response_len_in_char: 1085.2333,aime2024/accuracy: 0.0333,gpqa_diamond/response_len_in_char: 1022.0202,gpqa_diamond/accuracy: 0.0202,eval_accuracy: 0.0765
2025-04-09 04:51:17.556 | DEBUG    | orz.ppo.trainer:make_experience:287 - starting make_experience
2025-04-09 04:51:17.556 | DEBUG    | orz.ppo.trainer:make_experience:288 - (before query branch) prompt batch size (bs): len(all_inputs): 8
2025-04-09 04:51:17.556 | DEBUG    | orz.ppo.trainer:make_experience:531 - 
--- Policy Branch ---

2025-04-09 04:51:17.556 | DEBUG    | orz.ppo.trainer:make_experience:532 - (before policy branch) prompt batch size (bs): len(all_inputs): 8
2025-04-09 04:51:17.556 | DEBUG    | orz.ppo.trainer:make_experience:533 - (before policy branch) sample all_inputs[0]: ("A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nLet $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\\overline{AA'}$ and $\\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\\overline{A'B'}$.\nAssistant: <think>", {'prompt': "A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nLet $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\\overline{AA'}$ and $\\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\\overline{A'B'}$.\nAssistant: <think>", 'answer': '\\frac{120\\sqrt{2}}{11}', 'target': '\\frac{120\\sqrt{2}}{11}'})
2025-04-09 04:51:17.557 | INFO     | orz.ppo.trainer:make_experience:564 - start generation
2025-04-09 04:52:16.100 | INFO     | orz.ppo.trainer:make_experience:567 - generate local rollout batch done
2025-04-09 04:52:16.100 | INFO     | orz.ppo.trainer:make_experience:552 - Generate sequences via vllm engines, time cost: 58.54s
2025-04-09 04:52:16.100 | DEBUG    | orz.ppo.trainer:make_experience:576 - 

INSPECT POLICY BRANCH PROMPTS AND RESPONSES
2025-04-09 04:52:16.100 | DEBUG    | orz.ppo.trainer:make_experience:577 - (policy branch) sample prompt, all_inputs[0]: ("A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nLet $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\\overline{AA'}$ and $\\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\\overline{A'B'}$.\nAssistant: <think>", {'prompt': "A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nLet $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\\overline{AA'}$ and $\\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\\overline{A'B'}$.\nAssistant: <think>", 'answer': '\\frac{120\\sqrt{2}}{11}', 'target': '\\frac{120\\sqrt{2}}{11}'})

2025-04-09 04:52:16.100 | DEBUG    | orz.ppo.trainer:make_experience:578 - (policy branch) sample response, outputs[0]: {'response': " To solve this problem, we can first find the coordinates of points A' and B' using the given information. Then, we can calculate the distance between A' and B' using the distance formula. To find the coordinates of points A' and B', we can use the fact that the points lie on line y = x and that the lines AA' and BB' intersect at point C = (3, 7).</think>\n\n<answer> First, we find the equation of line AA': \nSince point A = (0, 5) and point C = (3, 7), the slope of line AA' is (7 - 5) / (3 - 0) = 2 / 3. Using the point-slope formula, the equation of line AA' is y - 5 = (2 / 3)(x - 0). Simplifying, we get y = (2 / 3)x + 5.\n\nNext, we find the equation of line BB':\nSince point B = (0, 15) and point C = (3, 7), the slope of line BB' is (7 - 15) / (3 - 0) = -8 / 3. Using the point-slope formula, the equation of line BB' is y - 15 = (-8 / 3)(x - 0). Simplifying, we get y = (-8 / 3)x + 15.\n\nNow, we can find the coordinates of points A' and B' by solving the system of equations formed by the equations of lines AA' and BB' with the equation of line y = x:\n1) (2 / 3)x + 5 = x\n2) (-8 / 3)x + 15 = x\n\nSolving equation 1, we get x = 3. Substituting this value back into the equation of line AA', we find y = (2 / 3)(3) + 5 = 7. So, the coordinates of point A' are (3, 7).\n\nSolving equation 2, we get x = 9. Substituting this value back into the equation of line BB', we find y = (-8 / 3)(9) + 15 = 3. So, the coordinates of point B' are (9, 3).\n\nFinally, we can calculate the distance between A' and B' using the distance formula:\nd = sqrt((9 - 3)² + (3 - 7)²) = sqrt(36 + 16) = sqrt(52) = 2√13. Thus, the length of $\\overline{A'B'}$ is 2√13</answer>", 'iscorrect': False, 'stop_reason': 'stop', 'final_answer': "First, we find the equation of line AA': \nSince point A = (0, 5) and point C = (3, 7), the slope of line AA' is (7 - 5) / (3 - 0) = 2 / 3. Using the point-slope formula, the equation of line AA' is y - 5 = (2 / 3)(x - 0). Simplifying, we get y = (2 / 3)x + 5.\n\nNext, we find the equation of line BB':\nSince point B = (0, 15) and point C = (3, 7), the slope of line BB' is (7 - 15) / (3 - 0) = -8 / 3. Using the point-slope formula, the equation of line BB' is y - 15 = (-8 / 3)(x - 0). Simplifying, we get y = (-8 / 3)x + 15.\n\nNow, we can find the coordinates of points A' and B' by solving the system of equations formed by the equations of lines AA' and BB' with the equation of line y = x:\n1) (2 / 3)x + 5 = x\n2) (-8 / 3)x + 15 = x\n\nSolving equation 1, we get x = 3. Substituting this value back into the equation of line AA', we find y = (2 / 3)(3) + 5 = 7. So, the coordinates of point A' are (3, 7).\n\nSolving equation 2, we get x = 9. Substituting this value back into the equation of line BB', we find y = (-8 / 3)(9) + 15 = 3. So, the coordinates of point B' are (9, 3).\n\nFinally, we can calculate the distance between A' and B' using the distance formula:\nd = sqrt((9 - 3)² + (3 - 7)²) = sqrt(36 + 16) = sqrt(52) = 2√13. Thus, the length of $\\overline{A'B'}$ is 2√13", 'extra': {'prompt': "A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nLet $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\\overline{AA'}$ and $\\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\\overline{A'B'}$.\nAssistant: <think>", 'answer': '\\frac{120\\sqrt{2}}{11}', 'target': '\\frac{120\\sqrt{2}}{11}'}}


2025-04-09 04:52:38.772 | INFO     | __main__:custom_reward_fn:335 - [STEP 0] [policy_reward_fn/log]: - prompt: A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>

<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.
This is the problem:
Let $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\overline{AA'}$ and $\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\overline{A'B'}$.
Assistant: <think>

- output:  To solve this problem, we can first find the coordinates of points A' and B' using the given information. Then, we can calculate the distance between A' and B' using the distance formula. To find the coordinates of points A' and B', we can use the fact that the points lie on line y = x and that the lines AA' and BB' intersect at point C = (3, 7).</think>

<answer> First, we find the equation of line AA': 
Since point A = (0, 5) and point C = (3, 7), the slope of line AA' is (7 - 5) / (3 - 0) = 2 / 3. Using the point-slope formula, the equation of line AA' is y - 5 = (2 / 3)(x - 0). Simplifying, we get y = (2 / 3)x + 5.

Next, we find the equation of line BB':
Since point B = (0, 15) and point C = (3, 7), the slope of line BB' is (7 - 15) / (3 - 0) = -8 / 3. Using the point-slope formula, the equation of line BB' is y - 15 = (-8 / 3)(x - 0). Simplifying, we get y = (-8 / 3)x + 15.

Now, we can find the coordinates of points A' and B' by solving the system of equations formed by the equations of lines AA' and BB' with the equation of line y = x:
1) (2 / 3)x + 5 = x
2) (-8 / 3)x + 15 = x

Solving equation 1, we get x = 3. Substituting this value back into the equation of line AA', we find y = (2 / 3)(3) + 5 = 7. So, the coordinates of point A' are (3, 7).

Solving equation 2, we get x = 9. Substituting this value back into the equation of line BB', we find y = (-8 / 3)(9) + 15 = 3. So, the coordinates of point B' are (9, 3).

Finally, we can calculate the distance between A' and B' using the distance formula:
d = sqrt((9 - 3)² + (3 - 7)²) = sqrt(36 + 16) = sqrt(52) = 2√13. Thus, the length of $\overline{A'B'}$ is 2√13</answer>

- final_answer: First, we find the equation of line AA': 
Since point A = (0, 5) and point C = (3, 7), the slope of line AA' is (7 - 5) / (3 - 0) = 2 / 3. Using the point-slope formula, the equation of line AA' is y - 5 = (2 / 3)(x - 0). Simplifying, we get y = (2 / 3)x + 5.

Next, we find the equation of line BB':
Since point B = (0, 15) and point C = (3, 7), the slope of line BB' is (7 - 15) / (3 - 0) = -8 / 3. Using the point-slope formula, the equation of line BB' is y - 15 = (-8 / 3)(x - 0). Simplifying, we get y = (-8 / 3)x + 15.

Now, we can find the coordinates of points A' and B' by solving the system of equations formed by the equations of lines AA' and BB' with the equation of line y = x:
1) (2 / 3)x + 5 = x
2) (-8 / 3)x + 15 = x

Solving equation 1, we get x = 3. Substituting this value back into the equation of line AA', we find y = (2 / 3)(3) + 5 = 7. So, the coordinates of point A' are (3, 7).

Solving equation 2, we get x = 9. Substituting this value back into the equation of line BB', we find y = (-8 / 3)(9) + 15 = 3. So, the coordinates of point B' are (9, 3).

Finally, we can calculate the distance between A' and B' using the distance formula:
d = sqrt((9 - 3)² + (3 - 7)²) = sqrt(36 + 16) = sqrt(52) = 2√13. Thus, the length of $\overline{A'B'}$ is 2√13

- extras: prompt: A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>

<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.
This is the problem:
Let $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\overline{AA'}$ and $\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\overline{A'B'}$.
Assistant: <think>
answer: \frac{120\sqrt{2}}{11}
target: \frac{120\sqrt{2}}{11}


- is_correct: False
2025-04-09 04:52:38.889 | DEBUG    | __main__:custom_reward_fn:360 - [STEP 0] | avg_non_stop_count=0 | percent_score_0=88.52% | percent_score_0_5=0.00% | percent_score_1=11.48% | percent_score_1_exclude_0_5=11.48% | num_tokens=[576, 63, 136, 674, 377, 392, 684, 86, 511, 324, 318, 133, 549, 343, 291, 293, 331, 125, 82, 249, 226, 137, 318, 125, 126, 379, 788, 113, 180, 288, 189, 224, 167, 413, 445, 223, 111, 172, 423, 124, 154, 132, 106, 222, 175, 110, 190, 280, 202, 144, 162, 138, 174, 119, 215, 95, 178, 316, 116, 514, 267, 439, 258, 597] | stop_percentage=95.31
2025-04-09 04:55:34.413 | DEBUG    | __main__:custom_reward_fn:835 - Before balancing, len(evaluator_res_score_tensors): 44
2025-04-09 04:55:34.414 | DEBUG    | __main__:custom_reward_fn:842 - Final score values before balancing: [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -0.5, 0.0, 0.0, -0.5, -0.5, 1.0, 1.0, -0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]
2025-04-09 04:55:34.414 | DEBUG    | __main__:custom_reward_fn:843 - rf_verification_list: ['yes', 'no', 'no', 'no', 'no', 'no', 'yes', None, 'no', 'no', None, None, 'no', 'no', None, 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', None, 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no']
2025-04-09 04:55:34.414 | DEBUG    | __main__:custom_reward_fn:866 - group_1_yes: 10, group_1_no: 15
2025-04-09 04:55:34.414 | DEBUG    | __main__:custom_reward_fn:867 - group_0_yes: 7, group_0_no: 7
2025-04-09 04:55:34.414 | DEBUG    | __main__:custom_reward_fn:890 - Selected indices after balancing: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]
2025-04-09 04:55:34.415 | DEBUG    | __main__:custom_reward_fn:939 - After balancing, len(evaluator_res_score_tensors): 39
2025-04-09 04:55:34.415 | DEBUG    | __main__:custom_reward_fn:940 - final_filtered_scores: [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, -0.5, 0.0, 0.0, -0.5, -0.5, 1.0, -0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, -0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]
2025-04-09 04:55:34.415 | DEBUG    | __main__:custom_reward_fn:961 - [STEP 0] [Policy Evaluator Full Log]: 

# Policy Index:
0

# Prompt:
A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>

<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.
This is the problem:
Let $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\overline{AA'}$ and $\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\overline{A'B'}$.
Assistant: <think>

# Policy Response:
 To solve this problem, we can first find the coordinates of points A' and B' using the given information. Then, we can calculate the distance between A' and B' using the distance formula. To find the coordinates of points A' and B', we can use the fact that the points lie on line y = x and that the lines AA' and BB' intersect at point C = (3, 7).</think>

<answer> First, we find the equation of line AA': 
Since point A = (0, 5) and point C = (3, 7), the slope of line AA' is (7 - 5) / (3 - 0) = 2 / 3. Using the point-slope formula, the equation of line AA' is y - 5 = (2 / 3)(x - 0). Simplifying, we get y = (2 / 3)x + 5.

Next, we find the equation of line BB':
Since point B = (0, 15) and point C = (3, 7), the slope of line BB' is (7 - 15) / (3 - 0) = -8 / 3. Using the point-slope formula, the equation of line BB' is y - 15 = (-8 / 3)(x - 0). Simplifying, we get y = (-8 / 3)x + 15.

Now, we can find the coordinates of points A' and B' by solving the system of equations formed by the equations of lines AA' and BB' with the equation of line y = x:
1) (2 / 3)x + 5 = x
2) (-8 / 3)x + 15 = x

Solving equation 1, we get x = 3. Substituting this value back into the equation of line AA', we find y = (2 / 3)(3) + 5 = 7. So, the coordinates of point A' are (3, 7).

Solving equation 2, we get x = 9. Substituting this value back into the equation of line BB', we find y = (-8 / 3)(9) + 15 = 3. So, the coordinates of point B' are (9, 3).

Finally, we can calculate the distance between A' and B' using the distance formula:
d = sqrt((9 - 3)² + (3 - 7)²) = sqrt(36 + 16) = sqrt(52) = 2√13. Thus, the length of $\overline{A'B'}$ is 2√13</answer>

# p_correct:
N/A

# RG Prompt:
You are a math teacher. Grade the Solution, verifying correctness step by step. Use Expected Answer to find any erroneous step in the Solution.

Question: "Let $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\overline{AA'}$ and $\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\overline{A'B'}$."

Solution: "<think> To solve this problem, we can first find the coordinates of points A' and B' using the given information. Then, we can calculate the distance between A' and B' using the distance formula. To find the coordinates of points A' and B', we can use the fact that the points lie on line y = x and that the lines AA' and BB' intersect at point C = (3, 7).</think>

<answer> First, we find the equation of line AA': 
Since point A = (0, 5) and point C = (3, 7), the slope of line AA' is (7 - 5) / (3 - 0) = 2 / 3. Using the point-slope formula, the equation of line AA' is y - 5 = (2 / 3)(x - 0). Simplifying, we get y = (2 / 3)x + 5.

Next, we find the equation of line BB':
Since point B = (0, 15) and point C = (3, 7), the slope of line BB' is (7 - 15) / (3 - 0) = -8 / 3. Using the point-slope formula, the equation of line BB' is y - 15 = (-8 / 3)(x - 0). Simplifying, we get y = (-8 / 3)x + 15.

Now, we can find the coordinates of points A' and B' by solving the system of equations formed by the equations of lines AA' and BB' with the equation of line y = x:
1) (2 / 3)x + 5 = x
2) (-8 / 3)x + 15 = x

Solving equation 1, we get x = 3. Substituting this value back into the equation of line AA', we find y = (2 / 3)(3) + 5 = 7. So, the coordinates of point A' are (3, 7).

Solving equation 2, we get x = 9. Substituting this value back into the equation of line BB', we find y = (-8 / 3)(9) + 15 = 3. So, the coordinates of point B' are (9, 3).

Finally, we can calculate the distance between A' and B' using the distance formula:
d = sqrt((9 - 3)² + (3 - 7)²) = sqrt(36 + 16) = sqrt(52) = 2√13. Thus, the length of $\overline{A'B'}$ is 2√13</answer>" (INCORRECT)

Expected Answer: "<think>N/A"

Please output your Solution verification in the following format:
<think> Your Solution verification here </think>
<answer> X </answer> where X is either Yes or No.

Math Teacher Response: <think>

# RG Response:
 The solution provided is incorrect. The coordinates of points A' and B' were found correctly, but the distance between them was calculated incorrectly. The correct distance formula should be used to find the length of $\overline{A'B'}$.</think>
<answer> No </answer>

# RG Final Answer:
No

# RF Prompt:
You are a math teacher. Grade the Solution, verifying correctness step by step.

Question: "Let $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\overline{AA'}$ and $\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\overline{A'B'}$."

Solution: "<think> To solve this problem, we can first find the coordinates of points A' and B' using the given information. Then, we can calculate the distance between A' and B' using the distance formula. To find the coordinates of points A' and B', we can use the fact that the points lie on line y = x and that the lines AA' and BB' intersect at point C = (3, 7).</think>

<answer> First, we find the equation of line AA': 
Since point A = (0, 5) and point C = (3, 7), the slope of line AA' is (7 - 5) / (3 - 0) = 2 / 3. Using the point-slope formula, the equation of line AA' is y - 5 = (2 / 3)(x - 0). Simplifying, we get y = (2 / 3)x + 5.

Next, we find the equation of line BB':
Since point B = (0, 15) and point C = (3, 7), the slope of line BB' is (7 - 15) / (3 - 0) = -8 / 3. Using the point-slope formula, the equation of line BB' is y - 15 = (-8 / 3)(x - 0). Simplifying, we get y = (-8 / 3)x + 15.

Now, we can find the coordinates of points A' and B' by solving the system of equations formed by the equations of lines AA' and BB' with the equation of line y = x:
1) (2 / 3)x + 5 = x
2) (-8 / 3)x + 15 = x

Solving equation 1, we get x = 3. Substituting this value back into the equation of line AA', we find y = (2 / 3)(3) + 5 = 7. So, the coordinates of point A' are (3, 7).

Solving equation 2, we get x = 9. Substituting this value back into the equation of line BB', we find y = (-8 / 3)(9) + 15 = 3. So, the coordinates of point B' are (9, 3).

Finally, we can calculate the distance between A' and B' using the distance formula:
d = sqrt((9 - 3)² + (3 - 7)²) = sqrt(36 + 16) = sqrt(52) = 2√13. Thus, the length of $\overline{A'B'}$ is 2√13</answer>"

Please output your Solution verification in the following format:
<think> Your Solution verification here </think>
<answer> X </answer> where X is either Yes or No.

Math Teacher Response: <think>

# RF Response:
 I checked every step of the solution and I did not find any incorrect calculations or mistakes in the reasoning.</think>
<answer> Yes </answer>

# RF Final Score Value:
None

# RF Final Answer:
Yes

# Judge Prompt:
You are an evaluator supervisor. Your task is to judge whether the Evaluation Response correctly evaluates the given solution by comparing it to the Reference Ground Truth. Do not evaluate the underlying mathematical solution again—only assess if the Evaluation Response correctly reflects the errors highlighted by the Reference Ground Truth.
Follow this output format:
<think> [Your detailed step-by-step analysis] </think>
<answer> X </answer>

Question: "Two circles with radius  $2$  and radius  $4$  have a common center at P.  Points  $A, B,$  and  $C$  on the larger circle are the vertices of an equilateral triangle.  Point  $D$  is the intersection of the smaller circle and the line segment  $PB$ . Find the square of the area of triangle  $ADC$ ."

Solution: "<think> To solve this problem, we can first find the coordinates of points A' and B' using the given information. Then, we can calculate the distance between A' and B' using the distance formula. To find the coordinates of points A' and B', we can use the fact that the points lie on line y = x and that the lines AA' and BB' intersect at point C = (3, 7).</think>

<answer> First, we find the equation of line AA': 
Since point A = (0, 5) and point C = (3, 7), the slope of line AA' is (7 - 5) / (3 - 0) = 2 / 3. Using the point-slope formula, the equation of line AA' is y - 5 = (2 / 3)(x - 0). Simplifying, we get y = (2 / 3)x + 5.

Next, we find the equation of line BB':
Since point B = (0, 15) and point C = (3, 7), the slope of line BB' is (7 - 15) / (3 - 0) = -8 / 3. Using the point-slope formula, the equation of line BB' is y - 15 = (-8 / 3)(x - 0). Simplifying, we get y = (-8 / 3)x + 15.

Now, we can find the coordinates of points A' and B' by solving the system of equations formed by the equations of lines AA' and BB' with the equation of line y = x:
1) (2 / 3)x + 5 = x
2) (-8 / 3)x + 15 = x

Solving equation 1, we get x = 3. Substituting this value back into the equation of line AA', we find y = (2 / 3)(3) + 5 = 7. So, the coordinates of point A' are (3, 7).

Solving equation 2, we get x = 9. Substituting this value back into the equation of line BB', we find y = (-8 / 3)(9) + 15 = 3. So, the coordinates of point B' are (9, 3).

Finally, we can calculate the distance between A' and B' using the distance formula:
d = sqrt((9 - 3)² + (3 - 7)²) = sqrt(36 + 16) = sqrt(52) = 2√13. Thus, the length of $\overline{A'B'}$ is 2√13</answer>"

Evaluation Response: "<think> I checked every step of the solution and I did not find any incorrect calculations or mistakes in the reasoning.</think>
<answer> Yes </answer>"

Reference Ground Truth: "<think> The solution provided is incorrect. The coordinates of points A' and B' were found correctly, but the distance between them was calculated incorrectly. The correct distance formula should be used to find the length of $\overline{A'B'}$.</think>
<answer> No </answer>"

Please output your Evaluation Response verification in the following format:
<think> [Your detailed step-by-step analysis comparing the Evaluation Response with the Reference Ground Truth on how correct of an assessment the Evaluation Response is] </think>
<answer> X </answer> where X is either Yes or No. Yes means that the Evaluation Response correctly reflects the errors highlighted by the Reference Ground Truth, and No means it does not.

Evaluator Supervisor Response: <think>

# Judge Response:
 I will compare the Evaluation Response with the Reference Ground Truth to determine if the Evaluation Response correctly reflects the errors highlighted by the Reference Ground Truth.

The Evaluation Response states that the solution is correct and does not contain any incorrect calculations or mistakes in the reasoning. However, the Reference Ground Truth points out that the distance between points A' and B' was calculated incorrectly, and the correct distance formula should be used to find the length of $\overline{A'B'}$.

Since the Evaluation Response does not acknowledge the error in the distance calculation, it does not correctly reflect the errors highlighted by the Reference Ground Truth.</think>
<answer> No </answer>

# Judge Decision:
0.0

# RF Final Score Value:
None


2025-04-09 04:55:34.415 | INFO     | __main__:custom_reward_fn:968 - p_correct exists percentage: 37.50%
2025-04-09 04:55:34.415 | INFO     | __main__:custom_reward_fn:994 - RG match iscorrect percentage: 91.67%
2025-04-09 04:55:34.429 | INFO     | __main__:custom_reward_fn:1070 - [STEP 0] RF extraction rate: 82.81% over 128 responses, match rate: 50.00% over 106 valid extractions, yes percentage: 45.28% (48/106), GT iscorrect rate: 13.21% (14/106), yes+GT precision: 20.83% (10/48), no+notGT precision: 93.10% (54/58), yes recall: 71.43% (10/14), no recall: 58.70% (54/92)
2025-04-09 04:55:34.430 | INFO     | __main__:custom_reward_fn:1088 - RG extraction success: 98.44% of responses
2025-04-09 04:55:34.432 | INFO     | __main__:custom_reward_fn:1094 - RF extraction success: 83.59% of responses
2025-04-09 04:55:34.438 | INFO     | __main__:custom_reward_fn:1118 - Judge decisions equal rule-based iscorrect score: 26.56% (34/128)
2025-04-09 04:55:34.439 | INFO     | __main__:custom_reward_fn:1126 - Judge decisions = 0 when rule-based iscorrect score = 0: 81.82% (9/11)
2025-04-09 04:55:34.440 | INFO     | __main__:custom_reward_fn:1128 - Judge decisions: 52.34% 1's, 43.75% 0's, 96.09% valid (0 or 1) out of 128 decisions
2025-04-09 04:55:34.455 | INFO     | __main__:custom_reward_fn:1182 - avg_non_stop_count: 0.0000,avg_repeat_score: 0.0153,avg_reflection_pattern_score: 0.0000,avg_pass_at_n: 0.3750,avg_num_tokens: 265.7969,std_num_tokens: 165.4329,avg_correct_num_tokens: 176.8571,std_correct_num_tokens: 44.5884,avg_incorrect_num_tokens: 268.0555,std_incorrect_num_tokens: 160.6453
2025-04-09 04:55:34.467 | INFO     | orz.ppo.trainer:make_experience:593 - Calculate custom rewards, time cost: 198.37s
2025-04-09 04:55:34.467 | DEBUG    | orz.ppo.trainer:make_experience:609 - (policy branch) after custom reward calculation, len(all_prompts): 39
2025-04-09 04:55:34.482 | INFO     | orz.ppo.trainer:make_experience:617 - Packing samples, time cost: 0.01s
2025-04-09 04:55:55.720 | INFO     | orz.ppo.trainer:make_experience:643 - experiences size: 2
2025-04-09 04:55:55.721 | INFO     | orz.ppo.trainer:make_experience:633 - Inference and calculate values, log probs, rewards, kl divergence, time cost: 21.24s
2025-04-09 04:55:55.721 | DEBUG    | orz.ppo.trainer:make_experience:671 - [STEP 0] [Policy SAR Log]
# Policy Prompt
A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>

<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.
This is the problem:
Let $A = (0, 5)$ and $B = (0, 15)$. Points $A'$ and $B'$ are on the line $y = x$, and lines $\overline{AA'}$ and $\overline{BB'}$ intersect at point $C = (3, 7)$. Find the length of $\overline{A'B'}$.
Assistant: <think>

# Policy Response
 To solve this problem, we can first find the coordinates of points A' and B' using the given information. Then, we can calculate the distance between A' and B' using the distance formula. To find the coordinates of points A' and B', we can use the fact that the points lie on line y = x and that the lines AA' and BB' intersect at point C = (3, 7).</think>

<answer> First, we find the equation of line AA': 
Since point A = (0, 5) and point C = (3, 7), the slope of line AA' is (7 - 5) / (3 - 0) = 2 / 3. Using the point-slope formula, the equation of line AA' is y - 5 = (2 / 3)(x - 0). Simplifying, we get y = (2 / 3)x + 5.

Next, we find the equation of line BB':
Since point B = (0, 15) and point C = (3, 7), the slope of line BB' is (7 - 15) / (3 - 0) = -8 / 3. Using the point-slope formula, the equation of line BB' is y - 15 = (-8 / 3)(x - 0). Simplifying, we get y = (-8 / 3)x + 15.

Now, we can find the coordinates of points A' and B' by solving the system of equations formed by the equations of lines AA' and BB' with the equation of line y = x:
1) (2 / 3)x + 5 = x
2) (-8 / 3)x + 15 = x

Solving equation 1, we get x = 3. Substituting this value back into the equation of line AA', we find y = (2 / 3)(3) + 5 = 7. So, the coordinates of point A' are (3, 7).

Solving equation 2, we get x = 9. Substituting this value back into the equation of line BB', we find y = (-8 / 3)(9) + 15 = 3. So, the coordinates of point B' are (9, 3).

Finally, we can calculate the distance between A' and B' using the distance formula:
d = sqrt((9 - 3)² + (3 - 7)²) = sqrt(36 + 16) = sqrt(52) = 2√13. Thus, the length of $\overline{A'B'}$ is 2√13</answer>

# Policy Reward
0.0

# Policy Evaluator Prompt
You are a math teacher. Grade the Solution, verifying correctness step by step.

Question: "Two circles of radius 12 cm overlap such that each circle passes through the center of the other. Find the length of the common chord between these two circles, expressed in simplest radical form."

Solution: "<think>Let's denote the common chord as AB and the centers of the two circles as O1 and O2. Since O1 and O2 are the centers of the circles and they pass through each other's centers, the distance between O1 and O2 is equal to the radii, so O1O2 = 24 cm.

Now consider triangle O1AO2. Since it's an isosceles triangle (O1A = O1B = O2A = O2B = 12 cm, the radii of the circles), it can be divided into two right triangles by drawing the perpendicular bisector of the chord AB, which also passes through O1 and O2. Each of those right triangles has a hypotenuse of 12 cm (radius) and a base of half the length of AB (x). We can use the Pythagorean theorem to find x, then multiply it by 2 to get the length of AB.

(1 / 2)AB^2 + (12 cm)^2 = (16 cm)^2
(1 / 2)AB^2 + 144 cm^2 = 256 cm^2
(1 / 2)AB^2 = 112 cm^2
AB^2 = 224 cm^2
AB = sqrt(224) cm = 4 * sqrt(14) cm</think>

<answer>The length of the common chord AB between these two circles is <strong>4 * sqrt(14) cm</strong>.</answer>"

Please output your Solution verification in the following format:
<think> Your Solution verification here </think>
<answer> X </answer> where X is either Yes or No.

Math Teacher Response: <think>

# Policy Evaluator Response
 I am going to grade this solution step by step. Let's examine the solution step by step:

1. The problem states that each circle passes through the center of the other. Therefore, the distance between the centers of the two circles is equal to 2 * 12 cm = 24 cm. This part of the solution is correct.

2. The solution defines a triangle O1AO2 and divides it into two isosceles triangles O1AB and O2AB with their respective right angles. This is correct as well.

3. The next step involves applying the Pythagorean theorem to one of the right triangles formed by the common chord, the radii, and the line segment connecting the centers of the two circles. The lengths should be as follows:
   - Hypotenuse (radius): 12 cm
   - Base (half the common chord): x cm
   - Side (distance from center to perpendicular bisector of the chord): O1C (or O2C) = 16 cm (since 24 cm / 2 = 12 cm and the right angle means we can subtract 12 cm from each side to find O1C or O2C)

   Now, let's check if the initial Pythagorean theorem application is correct:
   x^2 + (12 cm)^2 = (16 cm)^2
   x^2 + 144 cm^2 = 256 cm^2
   x^2 = 112 cm^2
   x = sqrt(112) cm
   x = 4 * sqrt(7) cm (remember this is half the chord length)

   The solution however, mistakenly uses 16 cm as the hypotenuse; it should be the length from the center of the circle (O1 or O2) to the perpendicular bisector of the chord, which is 12 cm.

   We need to re-calculate the correct length of half the chord (x):
   x^2 + (12 cm)^2 = (12 cm)^2
   x^2 + 144 cm^2 = 144 cm^2
   x^2 = 0 cm^2
   x = 0 cm

   This result is not correct, suggesting an error in the setup. Let's recalculate correctly:

   The distance between the center of the circle and the common chord (which is half the distance between the two centers) is actually 12 cm (not 16 cm), as the centers of the circles are on the central perpendicular bisector of the chord. Thus, the correct equation is:

   x^2 + (12 cm)^2 = (12 cm)^2
   x^2 + 144 cm^2 = 144 cm^2
   x^2 = 144 cm^2 - 144 cm^2
   x^2 = 144 cm^2
   x = sqrt(144) cm
   x = 0 cm or x = 12 cm
   This indicates that the correct side length should be solved by:
   x^2 + (12 cm)^2 = (12 cm)^2
   x^2 + 144 cm^2 = 144 cm^2
   x^2 = 144 cm^2
   x = sqrt(144) cm
   x = 12 cm (but it's half of the chord)

4. The final step to get the length of the whole common chord AB would be to multiply it by 2: 2 * 12 cm = 24 cm.</think>

<answer> Yes </answer>

# Policy Evaluator Reward
0.0

# Exact Match is_correct Reward
False

# Ground Truth Answer
\frac{120\sqrt{2}}{11}
2025-04-09 04:55:56.232 | INFO     | orz.ppo.trainer:make_experience:689 - Calculate advantages and returns, time cost: 0.50s
2025-04-09 04:55:56.232 | INFO     | orz.ppo.trainer:make_experience:748 - avg_raw_rewards: -0.0357142873108387, avg_kl: 0.0, avg_response_length: 290.04017639160156, avg_orm_score: 0.0, avg_custom_rewards: -0.0357142873108387
2025-04-09 04:55:56.272 | INFO     | orz.ppo.trainer:make_experience:782 - Packing policy evaluator samples, time cost: 0.01s
2025-04-09 04:56:16.500 | INFO     | orz.ppo.trainer:make_experience:797 - Evaluator experiences size: 2
2025-04-09 04:56:16.501 | INFO     | orz.ppo.trainer:make_experience:791 - Evaluator Inference and calculate values, log probs, rewards, kl divergence, time cost: 20.23s
2025-04-09 04:56:17.005 | INFO     | orz.ppo.trainer:make_experience:807 - Calculate evaluator advantages and returns, time cost: 0.50s
2025-04-09 04:56:17.054 | INFO     | orz.ppo.trainer:train:144 - dumping replay buffer to /vc_data_blob/users/kevihuang/models/orz/orz_ckpt/debug_orz_7b_ppo_self_play__math__v1429__self_play_False/dumped_replay_buffer/iter0_replay_buffer.jsonl
2025-04-09 04:56:17.146 | INFO     | orz.ppo.trainer:train:139 - Dumping replay buffer, time cost: 0.12s
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Critic Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Actor Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]
2025-04-09 04:56:45.506 | INFO     | orz.ppo.trainer:ppo_local_train_critic:1969 - Critic model training, time cost: 28.20s
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Critic Train epoch [1/1]:   0%|          | 0/1 [00:28<?, ?it/s, critic_loss=0.185, values=0.0201, critic_lr=1e-7]Critic Train epoch [1/1]:   0%|          | 0/1 [00:28<?, ?it/s, critic_loss=0.185, values=0.0201, critic_lr=1e-7]
2025-04-09 04:56:47.722 | INFO     | orz.ppo.trainer:ppo_local_train_policy:1953 - Policy model training, time cost: 30.44s
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Actor Train epoch [1/1]:   0%|          | 0/1 [00:30<?, ?it/s, pg=-0.0221, ret=0.0203, glen=257, tlen=503, kl=0, act_lr=2e-8, ent=0.828]Actor Train epoch [1/1]:   0%|          | 0/1 [00:30<?, ?it/s, pg=-0.0221, ret=0.0203, glen=257, tlen=503, kl=0, act_lr=2e-8, ent=0.828]
2025-04-09 04:56:47.991 | INFO     | orz.ppo.trainer:train:171 - Actor and Critic model training, time cost: 30.71s
2025-04-09 04:56:47.991 | INFO     | orz.ppo.trainer:train:189 - {'policy_loss': -0.022055309265851974, 'actor_lr': 1.999999987845058e-08, 'clip_ratio': 0.0, 'entropy': 0.8284522891044617, 'kl': 0.0, 'response_length': 256.7496643066406, 'total_length': 502.95184326171875, 'exp_type': 0.5333333611488342, 'return': 0.020311348140239716, 'policy_update_steps': 1.0}
Episode [1/20]:   0%|          | 1/7110 [08:00<949:15:10, 480.70s/it]2025-04-09 04:56:47.992 | DEBUG    | orz.ppo.trainer:make_experience:287 - starting make_experience
2025-04-09 04:56:47.992 | DEBUG    | orz.ppo.trainer:make_experience:288 - (before query branch) prompt batch size (bs): len(all_inputs): 8
2025-04-09 04:56:47.992 | DEBUG    | orz.ppo.trainer:make_experience:531 - 
--- Policy Branch ---

2025-04-09 04:56:47.993 | DEBUG    | orz.ppo.trainer:make_experience:532 - (before policy branch) prompt batch size (bs): len(all_inputs): 8
2025-04-09 04:56:47.993 | DEBUG    | orz.ppo.trainer:make_experience:533 - (before policy branch) sample all_inputs[0]: ('A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nHow many pairs of two-digit positive integers have a difference of 50?\nAssistant: <think>', {'prompt': 'A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nHow many pairs of two-digit positive integers have a difference of 50?\nAssistant: <think>', 'answer': '40', 'target': '40'})
2025-04-09 04:56:47.993 | INFO     | orz.ppo.trainer:make_experience:564 - start generation
2025-04-09 04:58:11.071 | INFO     | orz.ppo.trainer:make_experience:567 - generate local rollout batch done
2025-04-09 04:58:11.071 | INFO     | orz.ppo.trainer:make_experience:552 - Generate sequences via vllm engines, time cost: 83.08s
2025-04-09 04:58:11.071 | DEBUG    | orz.ppo.trainer:make_experience:576 - 

INSPECT POLICY BRANCH PROMPTS AND RESPONSES
2025-04-09 04:58:11.071 | DEBUG    | orz.ppo.trainer:make_experience:577 - (policy branch) sample prompt, all_inputs[0]: ('A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nHow many pairs of two-digit positive integers have a difference of 50?\nAssistant: <think>', {'prompt': 'A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nHow many pairs of two-digit positive integers have a difference of 50?\nAssistant: <think>', 'answer': '40', 'target': '40'})

2025-04-09 04:58:11.071 | DEBUG    | orz.ppo.trainer:make_experience:578 - (policy branch) sample response, outputs[0]: {'response': ' First, I need to find the smallest pair of two-digit positive integers with a difference of 50. Since both integers should be positive, the smallest possible difference between two two-digit numbers is 10 - 9 = 1. Thus, the smallest pair of two-digit numbers with a difference of 50 would be (51, 101).\n\nNext, I need to find the largest pair of two-digit positive integers with a difference of 50. The largest two-digit number is 99. Therefore, the largest pair of two-digit numbers with a difference of 50 would be (149, 99).\n\nNow I need to find how many pairs of these numbers exists. I will start with the smallest number of the first pair and increase it by 1 each time until I reach the largest number of the second pair. I need to calculate the number of times I need to do this.\n\n51, 52, 53, ..., 149. </think>\n\n<answer> 149 - 51 + 1 = 99. There are 99 pairs of two-digit positive integers with a difference of 50. </answer>', 'iscorrect': False, 'stop_reason': 'stop', 'final_answer': '149 - 51 + 1 = 99. There are 99 pairs of two-digit positive integers with a difference of 50.', 'extra': {'prompt': 'A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>\n\n<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.\nThis is the problem:\nHow many pairs of two-digit positive integers have a difference of 50?\nAssistant: <think>', 'answer': '40', 'target': '40'}}


2025-04-09 04:58:11.251 | DEBUG    | __main__:custom_reward_fn:360 - [STEP 1] | avg_non_stop_count=0 | percent_score_0=88.52% | percent_score_0_5=0.00% | percent_score_1=11.48% | percent_score_1_exclude_0_5=11.48% | num_tokens=[253, 85, 77, 111, 331, 130, 371, 273, 978, 365, 51, 647, 168, 314, 312, 544, 301, 352, 445, 96, 849, 1120, 327, 838, 102, 192, 124, 276, 314, 306, 472, 74, 563, 181, 292, 436, 638, 194, 216, 516, 198, 104, 229, 105, 66, 218, 162, 147, 473, 249, 541, 428, 301, 487, 142, 326, 425, 316, 213, 315, 287, 301, 463, 341] | stop_percentage=95.31
2025-04-09 05:17:14.885 | DEBUG    | __main__:custom_reward_fn:835 - Before balancing, len(evaluator_res_score_tensors): 59
2025-04-09 05:17:14.885 | DEBUG    | __main__:custom_reward_fn:842 - Final score values before balancing: [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, -0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, -0.5, 1.0, 0.0, 0.0, 0.0, 0.0, -0.5, 0.0, -0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, -0.5, 0.0, 0.0, 0.0]
2025-04-09 05:17:14.885 | DEBUG    | __main__:custom_reward_fn:843 - rf_verification_list: ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', None, 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', None, 'no', 'yes', 'yes', 'no', 'no', None, 'no', None, 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', None, 'yes', 'no', 'no', 'yes', 'yes', 'yes', None, 'yes', 'yes', 'yes']
2025-04-09 05:17:14.885 | DEBUG    | __main__:custom_reward_fn:866 - group_1_yes: 6, group_1_no: 16
2025-04-09 05:17:14.885 | DEBUG    | __main__:custom_reward_fn:867 - group_0_yes: 20, group_0_no: 11
2025-04-09 05:17:14.885 | DEBUG    | __main__:custom_reward_fn:890 - Selected indices after balancing: [0, 2, 3, 4, 5, 7, 8, 9, 10, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 48, 49, 50, 51, 52, 53, 55, 56, 57]
2025-04-09 05:17:14.886 | DEBUG    | __main__:custom_reward_fn:939 - After balancing, len(evaluator_res_score_tensors): 40
2025-04-09 05:17:14.886 | DEBUG    | __main__:custom_reward_fn:940 - final_filtered_scores: [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, -0.5, 1.0, 1.0, -0.5, 0.0, 0.0, 0.0, 0.0, -0.5, 0.0, -0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, -0.5, 0.0, 1.0, 0.0, 0.0, 0.0, -0.5, 0.0, 0.0]
2025-04-09 05:17:14.886 | DEBUG    | __main__:custom_reward_fn:961 - [STEP 1] [Policy Evaluator Full Log]: 

# Policy Index:
0

# Prompt:
A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>

<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.
This is the problem:
How many pairs of two-digit positive integers have a difference of 50?
Assistant: <think>

# Policy Response:
 First, I need to find the smallest pair of two-digit positive integers with a difference of 50. Since both integers should be positive, the smallest possible difference between two two-digit numbers is 10 - 9 = 1. Thus, the smallest pair of two-digit numbers with a difference of 50 would be (51, 101).

Next, I need to find the largest pair of two-digit positive integers with a difference of 50. The largest two-digit number is 99. Therefore, the largest pair of two-digit numbers with a difference of 50 would be (149, 99).

Now I need to find how many pairs of these numbers exists. I will start with the smallest number of the first pair and increase it by 1 each time until I reach the largest number of the second pair. I need to calculate the number of times I need to do this.

51, 52, 53, ..., 149. </think>

<answer> 149 - 51 + 1 = 99. There are 99 pairs of two-digit positive integers with a difference of 50. </answer>

# p_correct:
 To solve this problem, I'll consider the two-digit numbers from 10 to 99. The smallest possible pair is (10, 60) and the largest possible pair is (49, 99). I'll calculate the number of pairs by counting the number of valid pairs incrementally. </think>

<answer> 40 </answer>

# RG Prompt:
You are a math teacher. Grade the Solution, verifying correctness step by step. Use Expected Answer to find any erroneous step in the Solution.

Question: "How many pairs of two-digit positive integers have a difference of 50?"

Solution: "<think> First, I need to find the smallest pair of two-digit positive integers with a difference of 50. Since both integers should be positive, the smallest possible difference between two two-digit numbers is 10 - 9 = 1. Thus, the smallest pair of two-digit numbers with a difference of 50 would be (51, 101).

Next, I need to find the largest pair of two-digit positive integers with a difference of 50. The largest two-digit number is 99. Therefore, the largest pair of two-digit numbers with a difference of 50 would be (149, 99).

Now I need to find how many pairs of these numbers exists. I will start with the smallest number of the first pair and increase it by 1 each time until I reach the largest number of the second pair. I need to calculate the number of times I need to do this.

51, 52, 53, ..., 149. </think>

<answer> 149 - 51 + 1 = 99. There are 99 pairs of two-digit positive integers with a difference of 50. </answer>" (INCORRECT)

Expected Answer: "<think> To solve this problem, I'll consider the two-digit numbers from 10 to 99. The smallest possible pair is (10, 60) and the largest possible pair is (49, 99). I'll calculate the number of pairs by counting the number of valid pairs incrementally. </think>

<answer> 40 </answer>"

Please output your Solution verification in the following format:
<think> Your Solution verification here </think>
<answer> X </answer> where X is either Yes or No.

Math Teacher Response: <think>

# RG Response:
 The solution provided is incorrect. The smallest pair of two-digit positive integers with a difference of 50 is (10, 60), not (51, 101). The largest pair is (49, 99), not (149, 99). The correct approach is to consider the two-digit numbers from 10 to 99 and count the number of valid pairs incrementally. </think>
<answer> No </answer>

# RG Final Answer:
No

# RF Prompt:
You are a math teacher. Grade the Solution, verifying correctness step by step.

Question: "How many pairs of two-digit positive integers have a difference of 50?"

Solution: "<think> First, I need to find the smallest pair of two-digit positive integers with a difference of 50. Since both integers should be positive, the smallest possible difference between two two-digit numbers is 10 - 9 = 1. Thus, the smallest pair of two-digit numbers with a difference of 50 would be (51, 101).

Next, I need to find the largest pair of two-digit positive integers with a difference of 50. The largest two-digit number is 99. Therefore, the largest pair of two-digit numbers with a difference of 50 would be (149, 99).

Now I need to find how many pairs of these numbers exists. I will start with the smallest number of the first pair and increase it by 1 each time until I reach the largest number of the second pair. I need to calculate the number of times I need to do this.

51, 52, 53, ..., 149. </think>

<answer> 149 - 51 + 1 = 99. There are 99 pairs of two-digit positive integers with a difference of 50. </answer>"

Please output your Solution verification in the following format:
<think> Your Solution verification here </think>
<answer> X </answer> where X is either Yes or No.

Math Teacher Response: <think>

# RF Response:
 First, let's verify the steps taken in the original solution.
Step 1: The smallest pair of two-digit positive integers with a difference of 50 was correctly identified as (51, 101).
Step 2: The largest pair of two-digit positive integers with a difference of 50 was incorrectly identified as (149, 99). The corrected pair should be (99, 49).
Step 3: The calculation of the number of pairs was based on an incorrect range. We need to recalculate using the correct range of smallest to largest numbers (51 to 99).</think>
<answer> No </answer>

# RF Final Score Value:
0.0

# RF Final Answer:
No

# Judge Prompt:
You are an evaluator supervisor. Your task is to judge whether the Evaluation Response correctly evaluates the given solution by comparing it to the Reference Ground Truth. Do not evaluate the underlying mathematical solution again—only assess if the Evaluation Response correctly reflects the errors highlighted by the Reference Ground Truth.
Follow this output format:
<think> [Your detailed step-by-step analysis] </think>
<answer> X </answer>

Question: "Paul tosses a fair 8-sided die. If the roll is a prime number, then he wins that amount in dollars. If the roll is composite, he wins nothing unless he rolls the highest composite number on the die, in which case he loses twice that amount in dollars. Otherwise, he gains 2 dollars. What is the expected value of his winnings on one die toss? Express your answer as a dollar value to the nearest cent."

Solution: "<think> First, I need to find the smallest pair of two-digit positive integers with a difference of 50. Since both integers should be positive, the smallest possible difference between two two-digit numbers is 10 - 9 = 1. Thus, the smallest pair of two-digit numbers with a difference of 50 would be (51, 101).

Next, I need to find the largest pair of two-digit positive integers with a difference of 50. The largest two-digit number is 99. Therefore, the largest pair of two-digit numbers with a difference of 50 would be (149, 99).

Now I need to find how many pairs of these numbers exists. I will start with the smallest number of the first pair and increase it by 1 each time until I reach the largest number of the second pair. I need to calculate the number of times I need to do this.

51, 52, 53, ..., 149. </think>

<answer> 149 - 51 + 1 = 99. There are 99 pairs of two-digit positive integers with a difference of 50. </answer>"

Evaluation Response: "<think> First, let's verify the steps taken in the original solution.
Step 1: The smallest pair of two-digit positive integers with a difference of 50 was correctly identified as (51, 101).
Step 2: The largest pair of two-digit positive integers with a difference of 50 was incorrectly identified as (149, 99). The corrected pair should be (99, 49).
Step 3: The calculation of the number of pairs was based on an incorrect range. We need to recalculate using the correct range of smallest to largest numbers (51 to 99).</think>
<answer> No </answer>"

Reference Ground Truth: "<think> The solution provided is incorrect. The smallest pair of two-digit positive integers with a difference of 50 is (10, 60), not (51, 101). The largest pair is (49, 99), not (149, 99). The correct approach is to consider the two-digit numbers from 10 to 99 and count the number of valid pairs incrementally. </think>
<answer> No </answer>"

Please output your Evaluation Response verification in the following format:
<think> [Your detailed step-by-step analysis comparing the Evaluation Response with the Reference Ground Truth on how correct of an assessment the Evaluation Response is] </think>
<answer> X </answer> where X is either Yes or No. Yes means that the Evaluation Response correctly reflects the errors highlighted by the Reference Ground Truth, and No means it does not.

Evaluator Supervisor Response: <think>

# Judge Response:
 The Evaluation Response correctly identifies that the original solution is incorrect and provides a corrected pair of two-digit positive integers with a difference of 50. However, it does not mention the smallest pair of two-digit positive integers with a difference of 50, which is (10, 60) according to the Reference Ground Truth. The Evaluation Response also does not mention the correct approach to count the number of valid pairs incrementally. </think>
<answer> No </answer>

# Judge Decision:
0.0

# RF Final Score Value:
0.0


2025-04-09 05:17:14.887 | INFO     | __main__:custom_reward_fn:968 - p_correct exists percentage: 50.00%
2025-04-09 05:17:14.887 | INFO     | __main__:custom_reward_fn:994 - RG match iscorrect percentage: 96.88%
2025-04-09 05:17:14.900 | INFO     | __main__:custom_reward_fn:1070 - [STEP 1] RF extraction rate: 84.38% over 128 responses, match rate: 46.88% over 108 valid extractions, yes percentage: 45.37% (49/108), GT iscorrect rate: 10.19% (11/108), yes+GT precision: 12.24% (6/49), no+notGT precision: 91.53% (54/59), yes recall: 54.55% (6/11), no recall: 55.67% (54/97)
2025-04-09 05:17:14.902 | INFO     | __main__:custom_reward_fn:1088 - RG extraction success: 93.75% of responses
2025-04-09 05:17:14.903 | INFO     | __main__:custom_reward_fn:1094 - RF extraction success: 86.72% of responses
2025-04-09 05:17:14.910 | INFO     | __main__:custom_reward_fn:1118 - Judge decisions equal rule-based iscorrect score: 33.59% (43/128)
2025-04-09 05:17:14.912 | INFO     | __main__:custom_reward_fn:1126 - Judge decisions = 0 when rule-based iscorrect score = 0: 84.00% (21/25)
2025-04-09 05:17:14.912 | INFO     | __main__:custom_reward_fn:1128 - Judge decisions: 46.88% 1's, 43.75% 0's, 90.62% valid (0 or 1) out of 128 decisions
2025-04-09 05:17:14.928 | INFO     | __main__:custom_reward_fn:1182 - avg_non_stop_count: 0.0000,avg_repeat_score: 0.0145,avg_reflection_pattern_score: 0.0000,avg_pass_at_n: 0.5000,avg_num_tokens: 329.2344,std_num_tokens: 217.5025,avg_correct_num_tokens: 505.4286,std_correct_num_tokens: 387.8932,avg_incorrect_num_tokens: 286.6852,std_incorrect_num_tokens: 144.7690
2025-04-09 05:17:14.941 | INFO     | orz.ppo.trainer:make_experience:593 - Calculate custom rewards, time cost: 1143.87s
2025-04-09 05:17:14.941 | DEBUG    | orz.ppo.trainer:make_experience:609 - (policy branch) after custom reward calculation, len(all_prompts): 40
2025-04-09 05:17:14.961 | INFO     | orz.ppo.trainer:make_experience:617 - Packing samples, time cost: 0.02s
2025-04-09 05:17:34.008 | INFO     | orz.ppo.trainer:make_experience:643 - experiences size: 2
2025-04-09 05:17:34.008 | INFO     | orz.ppo.trainer:make_experience:633 - Inference and calculate values, log probs, rewards, kl divergence, time cost: 19.05s
2025-04-09 05:17:34.009 | DEBUG    | orz.ppo.trainer:make_experience:671 - [STEP 1] [Policy SAR Log]
# Policy Prompt
A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e. your response format should be: <think> reasoning process here </think>

<answer> answer here </answer>. User: You must put your answer inside <answer> </answer> tags, i.e., <answer> answer here </answer>.
This is the problem:
How many pairs of two-digit positive integers have a difference of 50?
Assistant: <think>

# Policy Response
 First, I need to find the smallest pair of two-digit positive integers with a difference of 50. Since both integers should be positive, the smallest possible difference between two two-digit numbers is 10 - 9 = 1. Thus, the smallest pair of two-digit numbers with a difference of 50 would be (51, 101).

Next, I need to find the largest pair of two-digit positive integers with a difference of 50. The largest two-digit number is 99. Therefore, the largest pair of two-digit numbers with a difference of 50 would be (149, 99).

Now I need to find how many pairs of these numbers exists. I will start with the smallest number of the first pair and increase it by 1 each time until I reach the largest number of the second pair. I need to calculate the number of times I need to do this.

51, 52, 53, ..., 149. </think>

<answer> 149 - 51 + 1 = 99. There are 99 pairs of two-digit positive integers with a difference of 50. </answer>

# Policy Reward
0.0

# Policy Evaluator Prompt
You are a math teacher. Grade the Solution, verifying correctness step by step.

Question: "How many pairs of two-digit positive integers have a difference of 50?"

Solution: "<think> First, I need to find the smallest pair of two-digit positive integers with a difference of 50. Since both integers should be positive, the smallest possible difference between two two-digit numbers is 10 - 9 = 1. Thus, the smallest pair of two-digit numbers with a difference of 50 would be (51, 101).

Next, I need to find the largest pair of two-digit positive integers with a difference of 50. The largest two-digit number is 99. Therefore, the largest pair of two-digit numbers with a difference of 50 would be (149, 99).

Now I need to find how many pairs of these numbers exists. I will start with the smallest number of the first pair and increase it by 1 each time until I reach the largest number of the second pair. I need to calculate the number of times I need to do this.

51, 52, 53, ..., 149. </think>

<answer> 149 - 51 + 1 = 99. There are 99 pairs of two-digit positive integers with a difference of 50. </answer>"

Please output your Solution verification in the following format:
<think> Your Solution verification here </think>
<answer> X </answer> where X is either Yes or No.

Math Teacher Response: <think>

# Policy Evaluator Response
 First, let's verify the steps taken in the original solution.
Step 1: The smallest pair of two-digit positive integers with a difference of 50 was correctly identified as (51, 101).
Step 2: The largest pair of two-digit positive integers with a difference of 50 was incorrectly identified as (149, 99). The corrected pair should be (99, 49).
Step 3: The calculation of the number of pairs was based on an incorrect range. We need to recalculate using the correct range of smallest to largest numbers (51 to 99).</think>
<answer> No </answer>

# Policy Evaluator Reward
0.0

# Exact Match is_correct Reward
False

# Ground Truth Answer
40
2025-04-09 05:17:34.438 | INFO     | orz.ppo.trainer:make_experience:689 - Calculate advantages and returns, time cost: 0.43s
2025-04-09 05:17:34.439 | INFO     | orz.ppo.trainer:make_experience:748 - avg_raw_rewards: 0.10549871809780598, avg_kl: 0.0, avg_response_length: 353.42967224121094, avg_orm_score: 0.0, avg_custom_rewards: 0.10549871809780598
2025-04-09 05:17:34.482 | INFO     | orz.ppo.trainer:make_experience:782 - Packing policy evaluator samples, time cost: 0.02s
2025-04-09 05:17:53.431 | INFO     | orz.ppo.trainer:make_experience:797 - Evaluator experiences size: 2
2025-04-09 05:17:53.432 | INFO     | orz.ppo.trainer:make_experience:791 - Evaluator Inference and calculate values, log probs, rewards, kl divergence, time cost: 18.95s
2025-04-09 05:17:53.948 | INFO     | orz.ppo.trainer:make_experience:807 - Calculate evaluator advantages and returns, time cost: 0.52s
2025-04-09 05:17:53.984 | INFO     | orz.ppo.trainer:train:144 - dumping replay buffer to /vc_data_blob/users/kevihuang/models/orz/orz_ckpt/debug_orz_7b_ppo_self_play__math__v1429__self_play_False/dumped_replay_buffer/iter1_replay_buffer.jsonl
2025-04-09 05:17:54.089 | INFO     | orz.ppo.trainer:train:139 - Dumping replay buffer, time cost: 0.12s
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Critic Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Actor Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]
2025-04-09 05:18:00.772 | INFO     | orz.ppo.trainer:ppo_local_train_policy:1953 - Policy model training, time cost: 6.68s
2025-04-09 05:18:00.772 | INFO     | orz.ppo.trainer:train:171 - Actor and Critic model training, time cost: 6.68s
2025-04-09 05:18:00.838 | INFO     | orz.ppo.trainer:ppo_local_train_critic:1969 - Critic model training, time cost: 6.72s
Traceback (most recent call last):
  File "/opt/conda/envs/ptca/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/envs/ptca/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/playground/orz_7b_ppo_self_play.py", line 2799, in <module>
  File "/opt/conda/envs/ptca/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/ptca/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/orz/exps/examples/ppo/ppo_base_exp.py", line 231, in run
    await self.trainer.train()
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/orz/ppo/trainer.py", line 172, in train
    status = await asyncio.gather(
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/orz/ppo/trainer.py", line 1954, in ppo_local_train_policy
    status = await self.policy_model.async_ppo_train(global_steps, replay_buffers)
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/orz/ppo/actors.py", line 339, in async_ppo_train
    return await asyncio.gather(
  File "/opt/conda/envs/ptca/lib/python3.10/asyncio/tasks.py", line 650, in _wrap_awaitable
    return (yield from awaitable.__await__())
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::PolicyRayActorBase.ppo_train()[39m (pid=1131469, ip=10.4.35.60, actor_id=2a1fc9718f7d0eef845b823601000000, repr=<orz.ppo.actors.PolicyRayActorBase object at 0x7fdab9878e50>)
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/orz/ppo/actors.py", line 448, in ppo_train
    status = self.training_step(experience, global_steps, local_step, accumulation_steps)
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/orz/ppo/actors.py", line 597, in training_step
    action_log_probs_all = torch.nn.functional.log_softmax(action_logits, dim=-1)
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/venv/lib/python3.10/site-packages/torch/nn/functional.py", line 2248, in log_softmax
    ret = input.log_softmax(dim)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.45 GiB. GPU 0 has a total capacity of 79.15 GiB of which 2.64 GiB is free. Process 749795 has 70.08 GiB memory in use. Process 753312 has 6.42 GiB memory in use. Of the allocated memory 65.81 GiB is allocated by PyTorch, and 2.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(PolicyRayActorBase pid=963645, ip=10.4.36.252)[0m Actor Train epoch [1/1]:   0%|          | 0/1 [00:06<?, ?it/s]
[36m(get_repeat_score pid=1733980)[0m [2025-04-09 04:52:21,501] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[36m(get_repeat_score pid=1733980)[0m [2025-04-09 04:52:21,504] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)
[36m(pid=956004, ip=10.4.38.42)[0m [2025-04-09 04:52:26,613] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.[32m [repeated 50x across cluster][0m
[36m(pid=956004, ip=10.4.38.42)[0m [2025-04-09 04:52:26,616] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)[32m [repeated 50x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Invalidate trace cache @ step 838 and module 0: cache has only 838 modules
[36m(pid=956536, ip=10.4.38.42)[0m [2025-04-09 04:52:27,626] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.[32m [repeated 13x across cluster][0m
[36m(pid=956536, ip=10.4.38.42)[0m [2025-04-09 04:52:27,629] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)[32m [repeated 13x across cluster][0m
[36m(CriticRayActorBase pid=1131862, ip=10.4.35.60)[0m Invalidate trace cache @ step 838 and module 0: cache has only 838 modules[32m [repeated 2x across cluster][0m
Episode [1/20]:   0%|          | 1/7110 [29:16<3468:38:50, 1756.52s/it]
