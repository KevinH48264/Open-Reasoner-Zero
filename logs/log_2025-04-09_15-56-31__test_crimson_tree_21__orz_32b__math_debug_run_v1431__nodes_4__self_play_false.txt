[2025-04-09 15:56:43,628] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2025-04-09 15:56:50.750 | INFO     | __main__:PPOExpConfig:162 - prompt_data: ['data/orz_math_57k_collected.json'], eval_prompt_data: ['data/eval_data/math500.json', 'data/eval_data/aime2024.json', 'data/eval_data/gpqa_diamond.json'], prompt_data_probs: [1.0]
2025-04-09 15:56:50.761 | INFO     | __main__:<module>:2758 - --------- config key ---------                  ------ value ------
seed                                            42
ref_num_nodes                                   12
ref_num_gpus_per_node                           1
reward_num_nodes                                12
reward_num_gpus_per_node                        1
actor_num_nodes                                 12
actor_num_gpus_per_node                         1
critic_num_nodes                                12
critic_num_gpus_per_node                        1
colocate_critic_reward                          True
colocate_actor_ref                              True
colocate_all                                    True
vllm_num_engines                                2
vllm_tensor_parallel_size                       4
vllm_sync_backend                               nccl
local_rank                                      -1
pretrain                                        Qwen/Qwen2.5-32B
critic_pretrain                                 Qwen/Qwen2.5-32B
reward_pretrain                                 <class 'NoneType'>
ckpt_path                                       /vc_data_blob/users/kevihuang/models/orz/orz_ckpt/debug_orz_7b_ppo_self_play__math__v1431__self_play_False
save_path                                       /vc_data_blob/users/kevihuang/models/orz/orz_ckpt/debug_orz_7b_ppo_self_play__math__v1431__self_play_False
tensorboard_log_dir                             orz_logs/debug_orz_7b_ppo_self_play__math__v1431__self_play_False
prompt_data                                     <class 'omegaconf.listconfig.ListConfig'>
load_checkpoint                                 True
zero_stage                                      3
bf16                                            True
zpg                                             1
adam_offload                                    False
flash_attn                                      True
grad_accum_dtype                                <class 'NoneType'>
disable_trace_cache                             False
gradient_checkpointing                          True
gradient_checkpointing_use_reentrant            False
disable_fast_tokenizer                          False
target_modules                                  all-linear
enable_prefix_caching                           True
enable_chunked_prefill                          False
max_num_batched_tokens                          2048
enforce_eager                                   False
gpu_memory_utilization                          0.5
eval_steps                                      -1
save_steps                                      -1
save_interval                                   50
actor_learning_rate                             1e-06
critic_learning_rate                            5e-06
num_episodes                                    20
max_epochs                                      1
prompt_max_len                                  8000
generate_max_len                                8000
train_batch_size                                256
micro_train_batch_size                          1
rollout_batch_size                              8
micro_rollout_batch_size                        128
micro_forward_batch_size                        1
policy_update_steps                             1
critic_update_steps                             1
max_len                                         8192
max_norm                                        1.0
num_warmup_steps                                50
l2                                              0.0
eps_clip                                        0.2
value_clip                                      0.2
lambd                                           1.0
gamma                                           1.0
normalize_reward                                True
top_p                                           1.0
temperature                                     1.0
freezing_actor_steps                            -1
n_samples_per_prompt                            8
kl_target                                       <class 'NoneType'>
init_kl_coef                                    0
use_kl_estimator_k3                             True
use_abs_kl                                      False
use_kl_loss                                     True
kl_loss_coef                                    0.0
adam_betas                                      (0.9, 0.95)
reward_clip_range                               (-10, 10)
use_compute_reward_fn                           True
advantage_normalize                             True
value_head_prefix                               value_head
ref_reward_offload                              False
enable_eval                                     True
eval_interval                                   10
update_ref_every_epoch                          True
use_orm_score                                   False
train_num_nodes_per_group                       12
n_policy_evaluator_samples_per_policy_response  1
eval_prompt_data                                <class 'omegaconf.listconfig.ListConfig'>
prompt_data_probs                               <class 'omegaconf.listconfig.ListConfig'>
packing_max_len                                 16384
top_k                                           -1
stop                                            <class 'omegaconf.listconfig.ListConfig'>
use_grpo                                        False
2025-04-09 15:56:50,840	INFO worker.py:1636 -- Connecting to existing Ray cluster at address: 10.4.33.154:6379...
2025-04-09 15:56:50,857	INFO worker.py:1821 -- Connected to Ray cluster.
Traceback (most recent call last):
  File "/opt/conda/envs/ptca/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/envs/ptca/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/playground/orz_7b_ppo_self_play.py", line 2765, in <module>
    asyncio.run(exp.run())
  File "/opt/conda/envs/ptca/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/ptca/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/orz/exps/examples/ppo/ppo_base_exp.py", line 228, in run
    await self.trainer.build_models(self.PolicyRayActor, self.CriticRayActor, self.RefRayActor, self.RewardRayActor)
  File "/opt/conda/envs/ptca/lib/python3.10/functools.py", line 981, in __get__
    val = self.func(instance)
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/playground/orz_7b_ppo_self_play.py", line 2683, in trainer
    vllm_engines = self.create_inference_engine()
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/orz/exps/examples/ppo/ppo_base_exp.py", line 194, in create_inference_engine
    return create_vllm_engines(
  File "/scratch/AzureNfsServer_INPUT1/data/users/kevihuang/projects/Open-Reasoner-Zero/orz/ppo/utils.py", line 430, in create_vllm_engines
    assert not colocate_with_actor, "colocate_with_actor is not supported when tensor_parallel_size > 1"
AssertionError: colocate_with_actor is not supported when tensor_parallel_size > 1
